{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idityaGE/Generative-AI/blob/main/LangChain%20-%20Basic%20to%20Advance/1_LangChain_Complete_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SUKUXK9h8XgL",
      "metadata": {
        "id": "SUKUXK9h8XgL"
      },
      "source": [
        "#**LangChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qo1DQXM18bgL",
      "metadata": {
        "id": "qo1DQXM18bgL"
      },
      "source": [
        "LangChain is a framework for developing applications powered by language models.\n",
        "\n",
        "- GitHub: https://github.com/hwchase17/langchain\n",
        "- Docs: https://python.langchain.com/v0.2/docs/introduction/\n",
        "\n",
        "### Overview:\n",
        "- Installation\n",
        "- LLMs\n",
        "- Prompt Templates\n",
        "- Chains\n",
        "- Agents and Tools\n",
        "- Memory\n",
        "- Document Loaders\n",
        "- Indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09CgA1RZkiC4",
      "metadata": {
        "id": "09CgA1RZkiC4"
      },
      "source": [
        "#**01: Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "X4tDdLTjkkk_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4tDdLTjkkk_",
        "outputId": "d7b68be8-3433-4f6b-89e5-1a9045ab04df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n",
            "  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.13 langchain-core-0.3.28 langchain_community-0.3.13 marshmallow-3.23.2 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sQHZiF38-Cps",
      "metadata": {
        "id": "sQHZiF38-Cps"
      },
      "source": [
        "#**02: Setup the Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9-mFf0Ql-KX2",
      "metadata": {
        "id": "9-mFf0Ql-KX2"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f31c4cc6",
      "metadata": {
        "id": "f31c4cc6"
      },
      "outputs": [],
      "source": [
        "os.environ['GOOGLE_API_KEY'] = \"AIzaSyCG-MnMDwpaMebAPktqpFP-IlnZ-rzL96s\"\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed0dc6a",
      "metadata": {
        "id": "9ed0dc6a"
      },
      "source": [
        "##**03: Large Language Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "516GZwvpnVpV",
      "metadata": {
        "id": "516GZwvpnVpV"
      },
      "source": [
        "The basic building block of LangChain is a Large Language Model which takes text as input and generates more text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4FDyNMY3sRMc",
      "metadata": {
        "id": "4FDyNMY3sRMc"
      },
      "source": [
        "Suppose we want to generate a company name based on the company description, so we will first initialize an OpenAI wrapper. In this case, since we want the output to be more random, we will intialize our model with high temprature."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eLqFwlXaH8f4",
      "metadata": {
        "id": "eLqFwlXaH8f4"
      },
      "source": [
        "The temperature parameter adjusts the randomness of the output. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rMOonq5OH97v",
      "metadata": {
        "id": "rMOonq5OH97v"
      },
      "source": [
        "temperature value--> how creative we want our model to be\n",
        "\n",
        "0 ---> temperature it means model is  very safe it is not taking any bets.\n",
        "\n",
        "1 --> it will take risk it might generate wrong output but it is very creative"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M9Y34zmZ8xyc",
      "metadata": {
        "id": "M9Y34zmZ8xyc"
      },
      "source": [
        "A generic interface for all LLMs. See all LLM providers: https://python.langchain.com/en/latest/modules/models/llms/integrations.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TB5tAUbT92Z7",
      "metadata": {
        "id": "TB5tAUbT92Z7"
      },
      "source": [
        "#**Open AI**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BszO_ZXrs95T",
      "metadata": {
        "id": "BszO_ZXrs95T"
      },
      "source": [
        "#**Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "w-az-0Ex9CaD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-az-0Ex9CaD",
        "outputId": "97070987-b8b9-4617-ce60-bf6650114e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.28)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.10.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "lJEy652utDdM",
      "metadata": {
        "id": "lJEy652utDdM"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n_nF4R5EtN_k",
      "metadata": {
        "id": "n_nF4R5EtN_k"
      },
      "source": [
        "And now we will pass in text and get  predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "VIUqmBl3tUgj",
      "metadata": {
        "id": "VIUqmBl3tUgj"
      },
      "outputs": [],
      "source": [
        "text=\"What would be a good company name for a company that makes colorful socks?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "g7itCa0q9rn7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7itCa0q9rn7",
        "outputId": "954837ab-55e6-47ea-9dba-a6f6154c55a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-652b389f66d4>:1: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(llm.predict(text))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Bold and Vibrant:**\n",
            "* Chromatic Threads\n",
            "* Rainbow Rush\n",
            "* Kaleidosock\n",
            "* Colorific Hosiery\n",
            "* Hue Haven\n",
            "\n",
            "**Whimsical and Playful:**\n",
            "* Sock Squad\n",
            "* Sole-ful Shenanigans\n",
            "* Toe-tally Awesome\n",
            "* Funky Footsies\n",
            "* Sock-a-doodle-doo\n",
            "\n",
            "**Sophisticated and Chic:**\n",
            "* Tonal Tapestry\n",
            "* Prismatic Panache\n",
            "* Vibrant Vista\n",
            "* Huetopia\n",
            "* Chromatic Couture\n",
            "\n",
            "**Punny and Memorable:**\n",
            "* Sock It to 'Em\n",
            "* Toe-tally Hosiery\n",
            "* Heel Yeah Socks\n",
            "* Yarn for the Soul\n",
            "* Toe-tally Crazy\n",
            "\n",
            "**Descriptive and Concise:**\n",
            "* Colorful Creations\n",
            "* Vibrant Hosiery\n",
            "* Rainbow Footwear\n",
            "* Kaleidoscope of Colors\n",
            "* Eye-Catching Socks\n"
          ]
        }
      ],
      "source": [
        "print(llm.predict(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "-s5lupvjFLVz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s5lupvjFLVz",
        "outputId": "1065f378-0be3-49ce-b102-b85067e4ab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='* Chromatic Soles\\n* Kaleidoscope Kicks\\n* Hues of Hosiery\\n* Technicolor Toes\\n* Rainbow Runners\\n* Vibrant Vestiges\\n* Motley Mitts\\n* Joyous Jewels\\n* Prismatic Pedals\\n* Spectrum Stitches' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-91c504db-00ec-4fbb-becb-89019dab0b27-0' usage_metadata={'input_tokens': 16, 'output_tokens': 53, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ],
      "source": [
        "print(llm.invoke(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EJIQT1FSn0Gl",
      "metadata": {
        "id": "EJIQT1FSn0Gl"
      },
      "source": [
        "#**Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fa352d5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa352d5f",
        "outputId": "548f8db9-23dc-4a57-bc86-fa67732261b1",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* **Emperors' Feast**\n",
            "* **Jade Pavilion**\n",
            "* **Celestial Dynasty**\n",
            "* **Golden Lotus**\n",
            "* **Orchid Garden**\n",
            "* **Silk Road Delights**\n",
            "* **Dragon's Breath**\n",
            "* **Phoenix's Wings**\n",
            "* **Celestial Palace**\n",
            "* **Imperial Court**\n"
          ]
        }
      ],
      "source": [
        "name = llm.predict(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b56e8581",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b56e8581",
        "outputId": "5972d8c2-65fd-4f8a-be7b-f55abcf7d240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Elegant and Sophisticated**\n",
            "\n",
            "* **Celestial Pavilion**\n",
            "* **Jade Dynasty**\n",
            "* **Imperial Court**\n",
            "* **Zenith Cuisine**\n",
            "* **The Scholar's Garden**\n",
            "* **Golden Phoenix**\n",
            "* **Emperor's Banquet**\n",
            "* **Celestial Harmony**\n",
            "* **ZenITH of Taste**\n",
            "* **Crimson Lotus**\n",
            "* **Symphony of Spices**\n",
            "* **Moonstone Terrace**\n",
            "* **Celestial Feast**\n",
            "* **Dragon's Breath**\n",
            "\n",
            "**Reflective of Chinese Culture and Cuisine**\n",
            "\n",
            "* **Mandarin Manor**\n",
            "* **Panda Garden**\n",
            "* **Grand Palace**\n",
            "* **Silk Road**\n",
            "* **Terracotta Feast**\n",
            "* **Confucius' Table**\n",
            "* **Dragon Throne**\n",
            "* **Lotus Blossom**\n",
            "* **Moon Gate**\n",
            "* **Wisteria Terrace**\n",
            "* **Orchid Garden**\n",
            "* **Zenith of Cuisine**\n",
            "* **Fusion of Flavors**\n",
            "* **Phoenix Rising**\n",
            "\n",
            "**Modern and Creative**\n",
            "\n",
            "* **Elevate Asia**\n",
            "* **Flavors of the Orient**\n",
            "* **Umami District**\n",
            "* **Zen Fusion**\n",
            "* **The Gastronomic Embassy**\n",
            "* **Zenith of Dining**\n",
            "* **Crimson Phoenix**\n",
            "* **Symphony of Tastes**\n",
            "* **Moonstone Terrace**\n",
            "* **Celestial Banquet**\n",
            "* **Dragon's Breath**\n"
          ]
        }
      ],
      "source": [
        "response=llm.predict(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bj6wjnKZ-bgU",
      "metadata": {
        "id": "bj6wjnKZ-bgU"
      },
      "source": [
        "#**Hugging Face**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iTsUW116-th1",
      "metadata": {
        "id": "iTsUW116-th1"
      },
      "source": [
        "#**Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "hDMLw7Yr-nQK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDMLw7Yr-nQK",
        "outputId": "0e474fb9-8812-41ea-86ad-a9a56f2575f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "B4w0ultA-icd",
      "metadata": {
        "id": "B4w0ultA-icd"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "W-pl8cXk-ie7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "W-pl8cXk-ie7",
        "outputId": "9997fd69-ec87-4fc3-dd17-6094ce6ae3ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-e545fdaa13f3>:3: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0.7, \"max_length\":64})\n",
            "<ipython-input-13-e545fdaa13f3>:5: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  llm(\"translate English to German: How old are you?\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wie alte sind Sie?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# https://huggingface.co/google/flan-t5-xl\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0.7, \"max_length\":64})\n",
        "\n",
        "llm(\"translate English to German: How old are you?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2MOh4uIm-xDQ",
      "metadata": {
        "id": "2MOh4uIm-xDQ"
      },
      "source": [
        "#**Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dmAwr5-d-z6F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmAwr5-d-z6F",
        "outputId": "dac33722-e98b-4b7d-bf0a-e04b625212bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-b6fa1e25b4d1>:1: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  name = llm.predict(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chinese restaurant\n"
          ]
        }
      ],
      "source": [
        "name = llm.predict(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n",
        "# name = llm.predict(\"I want to open a restaurant for Indian food. Suggest a fency name for this.\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = llm.invoke(\"What would be a good company name for a company that makes colorful socks?\")\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mrtoTCtacC5d",
        "outputId": "bb5bfd3a-ebdc-4d34-c4a9-ee6d0a84f4e0"
      },
      "id": "mrtoTCtacC5d",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sock mania'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0782a2dd",
      "metadata": {
        "id": "0782a2dd"
      },
      "source": [
        "##**04: Prompt Templates**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jszTHb6J_dNV",
      "metadata": {
        "id": "jszTHb6J_dNV"
      },
      "source": [
        "Currently in the above applications we are writing an entire prompt, if you are creating a user directed application then this is not an ideal case\n",
        "\n",
        "LangChain faciliates prompt management and optimization.\n",
        "\n",
        "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unU1DcEv7TWh",
      "metadata": {
        "id": "unU1DcEv7TWh"
      },
      "source": [
        "In many Large Language Model applications we donot pass the user input directly to the Large Language Model, we add the user input to a large piece of text called prompt template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IWqka6F_93QB",
      "metadata": {
        "id": "IWqka6F_93QB"
      },
      "source": [
        "#**Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7a306b9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a306b9d",
        "outputId": "b332f6a3-57a1-4f0f-f957-f458a9aa6457",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to open a restaurant for indian food. Suggest a fency name for this.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "p = prompt_template_name.format(cuisine=\"indian\")\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qlKeWd7B95-R",
      "metadata": {
        "id": "qlKeWd7B95-R"
      },
      "source": [
        "#**Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "qqJZBS9u8534",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqJZBS9u8534",
        "outputId": "1945b912-6cc8-4e33-d551-bbd40ebde774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sock mania\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "templ = prompt.format(product=\"colorful socks\")\n",
        "templ\n",
        "\n",
        "print(llm.predict(templ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af406b92",
      "metadata": {
        "id": "af406b92"
      },
      "source": [
        "##**05: Chains**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vGaSSUAIBHdU",
      "metadata": {
        "id": "vGaSSUAIBHdU"
      },
      "source": [
        "Combine LLMs and Prompts in multi-step workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lcjlXP7z_-k6",
      "metadata": {
        "id": "lcjlXP7z_-k6"
      },
      "source": [
        "Now as we have the  **model**:\n",
        "\n",
        "\n",
        "  llm = OpenAI(temperature=0.9)\n",
        "\n",
        "\n",
        "and the **Prompt Template**:\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "\n",
        "\n",
        "prompt.format(product=\"colorful socks\")\n",
        "\n",
        "\n",
        "Now using Chains we will link together model and the PromptTemplate and other Chains"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mIJx5zL2BbHJ",
      "metadata": {
        "id": "mIJx5zL2BbHJ"
      },
      "source": [
        "The simplest and most common type of Chain is LLMChain, which passes the input first to Prompt Template and then to Large Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5icZHtlDFrpI",
      "metadata": {
        "id": "5icZHtlDFrpI"
      },
      "source": [
        "LLMChain is responsible to execute the PromptTemplate, For every PromptTemplate we will specifically have an LLMChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MAUSugfLCZH-",
      "metadata": {
        "id": "MAUSugfLCZH-"
      },
      "source": [
        "#**Example 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "22NEqcvGGvHJ",
      "metadata": {
        "id": "22NEqcvGGvHJ"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bK-KESsGGOhY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bK-KESsGGOhY",
        "outputId": "3148d930-13ad-4c84-9306-15b2ee7b4e96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes colorful socks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "prompt.format(product=\"colorful socks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8KjGw4iXGUGJ",
      "metadata": {
        "id": "8KjGw4iXGUGJ"
      },
      "source": [
        "Whatever input text i am giving that will get assigned to this particular variable that is **product**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1gatUl_ICZOP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gatUl_ICZOP",
        "outputId": "9813639f-4e53-45f3-aac2-84a47b59a878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-033348973727>:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n",
            "<ipython-input-20-033348973727>:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chain.run(\"colorful socks\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Hue & Hues\n",
            "* Sock Spectrum\n",
            "* Colorific Toes\n",
            "* Kaleidoscopic Soles\n",
            "* Chromatic Threads\n",
            "* Vibrant Viridian\n",
            "* Ebullient Ensembles\n",
            "* Prismatic Pairs\n",
            "* Rainbow Republic\n",
            "* Spectrum Silks\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "response = chain.run(\"colorful socks\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O93s1iRICXNv",
      "metadata": {
        "id": "O93s1iRICXNv"
      },
      "source": [
        "#**Example 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "uLtIkYe6G7xK",
      "metadata": {
        "id": "uLtIkYe6G7xK"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ba65c213",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba65c213",
        "outputId": "7861a76e-b708-4d09-efc5-4ca327c2e9ae",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* **Cantina de Oro:** \"Golden Tavern\"\n",
            "* **El Palacio de Sazón:** \"The Palace of Flavors\"\n",
            "* **Hacienda de los Sabores:** \"Estate of Tastes\"\n",
            "* **Mi Casa, Su Mesa:** \"My Home, Your Table\"\n",
            "* **La Rosa de los Vientos:** \"The Rose of the Winds\" (implying a diverse menu)\n",
            "* **El Tesoro de Jalisco:** \"The Treasure of Jalisco\"\n",
            "* **La Luna Azul:** \"The Blue Moon\" (a celestial and enchanting name)\n",
            "* **La Fonda Noble:** \"The Noble Inn\"\n",
            "* **El Molino de las Aromas:** \"The Mill of Aromas\"\n",
            "* **El Portal de la Cocina:** \"The Gateway to the Kitchen\"\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "response=chain.run(\"Mexican\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e5ccee75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5ccee75",
        "outputId": "13896ea0-3718-4c99-c765-7368df38b7f7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest a fency name for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "* **Azteca's Solace**\n",
            "* **Casa de la Luna Escondida** (Hidden Moon House)\n",
            "* **El Huerto del Emperador** (The Emperor's Garden)\n",
            "* **Horizontes de Jalisco** (Jalisco's Horizons)\n",
            "* **La Corona de México** (The Crown of Mexico)\n",
            "* **Piedra Mágica** (Magic Stone)\n",
            "* **Rincón de Xcaret** (Xcaret's Corner)\n",
            "* **Sabor de Jalisco** (Flavor of Jalisco)\n",
            "* **Tierra Mágica** (Magic Land)\n",
            "* **Tres Cumbres** (Three Peaks)\n"
          ]
        }
      ],
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
        "response=chain.run(\"Mexican\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EMd9OQVNH7lK",
      "metadata": {
        "id": "EMd9OQVNH7lK"
      },
      "source": [
        "**Can we combine Multiple PromptTemplates, We will try to combine Multiple PromptTemplates**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nv_tlKtLJLIZ",
      "metadata": {
        "id": "nv_tlKtLJLIZ"
      },
      "source": [
        "**The output from the first PromptTemplate is passed to the next PromptTemplate as input**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a-6_6H-BJl9L",
      "metadata": {
        "id": "a-6_6H-BJl9L"
      },
      "source": [
        "#**To combine the Chain and  to set a sequence for that we use SimpleSequentialChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a98d9f",
      "metadata": {
        "id": "87a98d9f"
      },
      "source": [
        "##**Simple Sequential Chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "21098937",
      "metadata": {
        "id": "21098937"
      },
      "outputs": [],
      "source": [
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
        "\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
        ")\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d9fd9a79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9fd9a79",
        "outputId": "d4acf88f-41e1-4be2-9b03-fb5ee63fc944",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food. Suggest a fency name for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSuggest some menu items for 1. **Ananda Bhavan** (\"Abode of Bliss\")\n",
            "2. **Rasika** (\"Delightful\")\n",
            "3. **Sampoorna** (\"Complete\")\n",
            "4. **Ashirvad** (\"Blessing\")\n",
            "5. **Deva Bhojana** (\"Heavenly Cuisine\")\n",
            "6. **Maharaja's Feast**\n",
            "7. **Sapphire Tandoor**\n",
            "8. **Saffron Spice**\n",
            "9. **Turmeric Palace**\n",
            "10. **Namaste Nirvana** (\"Salutation to the Divine\")\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "**1. Ananda Bhavan**\n",
            "- Rasamalai: Sweetened condensed milk with saffron-infused dumplings\n",
            "- Paneer Tikka Masala: Creamy tomato-based sauce with grilled paneer cheese\n",
            "- Aloo Gobi: Sautéed potatoes and cauliflower with spices and herbs\n",
            "\n",
            "**2. Rasika**\n",
            "- Butter Chicken: Tangy tomato-based sauce with tender chicken\n",
            "- Dahi Bhalla: Lentil dumplings soaked in yogurt\n",
            "- Aloo Paratha: Whole-wheat flatbread stuffed with mashed potatoes\n",
            "\n",
            "**3. Sampoorna**\n",
            "- Thali: A complete Indian meal with rice, curries, vegetables, and bread\n",
            "- Biryani: Layered dish with basmati rice, vegetables, and meat\n",
            "- Lassi: Traditional yogurt-based drink\n",
            "\n",
            "**4. Ashirvad**\n",
            "- Chole Bhature: Chickpea curry with fluffy fried bread\n",
            "- Samosas: Triangular pastry filled with vegetables or meat\n",
            "- Kheer: Creamy rice pudding\n",
            "\n",
            "**5. Deva Bhojana**\n",
            "- Dosa: Thin, crispy crepe made from fermented lentils and rice\n",
            "- Idli: Steamed lentil and rice dumplings\n",
            "- Vada: Savory fried doughnut\n",
            "\n",
            "**6. Maharaja's Feast**\n",
            "- Rogan Josh: Aromatic lamb curry with Kashmiri spices\n",
            "- Fish Tikka: Grilled fish marinated in yogurt and spices\n",
            "- Kulfi: Traditional Indian ice cream\n",
            "\n",
            "**7. Sapphire Tandoor**\n",
            "- Tandoori Chicken: Chicken marinated in yogurt and spices, cooked in a tandoor oven\n",
            "- Naan: Soft, fluffy bread baked in a tandoor oven\n",
            "- Raita: Yogurt-based dip with vegetables\n",
            "\n",
            "**8. Saffron Spice**\n",
            "- Palak Paneer: Spinach-based curry with paneer cheese\n",
            "- Dal Makhani: Creamy lentil dish with butter and cream\n",
            "- Mutter Paneer: Peas and paneer with a mild tomato-based sauce\n",
            "\n",
            "**9. Turmeric Palace**\n",
            "- Chicken Tikka Masala: Classic Indian dish with grilled chicken in a creamy tomato-based sauce\n",
            "- Vegetable Korma: Mild vegetable curry with coconut milk and nuts\n",
            "- Basmati Rice: Aromatic long-grain rice\n",
            "\n",
            "**10. Namaste Nirvana**\n",
            "- Chai: Aromatic tea made with milk, spices, and ginger\n",
            "- Pakoras: Vegetable fritters coated in a chickpea batter\n",
            "- Gulab Jamun: Sweet, deep-fried dough balls soaked in syrup\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
        "\n",
        "content = chain.run(\"indian\")\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "njqmmiouJ6Uc",
      "metadata": {
        "id": "njqmmiouJ6Uc"
      },
      "source": [
        "**There is a issue with SimpleSequentialChain it only shows last input information**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hKVVpZo8KC38",
      "metadata": {
        "id": "hKVVpZo8KC38"
      },
      "source": [
        "#**To show the entire information i will use SequentialChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0386d05c",
      "metadata": {
        "id": "0386d05c"
      },
      "source": [
        "##**Sequential Chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "49dc0fae",
      "metadata": {
        "id": "49dc0fae"
      },
      "outputs": [],
      "source": [
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9dea8402",
      "metadata": {
        "id": "9dea8402"
      },
      "outputs": [],
      "source": [
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1ec1be10",
      "metadata": {
        "id": "1ec1be10"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, food_items_chain],\n",
        "    input_variables = ['cuisine'],\n",
        "    output_variables = ['restaurant_name', \"menu_items\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4653c540",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4653c540",
        "outputId": "2cc2b951-19bf-4378-9259-fefb0622bf98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food. Suggest a fency name for this.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-1321e5c28a21>:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  res = chain({\"cuisine\": \"indian\"})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSuggest some menu items for * **Ashoka's Feast**\n",
            "* **The Maharajah's Table**\n",
            "* **Indra's Nectar**\n",
            "* **Saffron and Star Anise**\n",
            "* **The Jewel of India**\n",
            "* **The Spice Merchant**\n",
            "* **The Tandoori Haven**\n",
            "* **The Mango Tree**\n",
            "* **The Royal Pavilion**\n",
            "* **The Palace of Flavors**.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "cuisine --> indian\n",
            "restaurant_name --> * **Ashoka's Feast**\n",
            "* **The Maharajah's Table**\n",
            "* **Indra's Nectar**\n",
            "* **Saffron and Star Anise**\n",
            "* **The Jewel of India**\n",
            "* **The Spice Merchant**\n",
            "* **The Tandoori Haven**\n",
            "* **The Mango Tree**\n",
            "* **The Royal Pavilion**\n",
            "* **The Palace of Flavors**\n",
            "menu_items --> **Ashoka's Feast**\n",
            "- Emperor's Delight: A rich and flavorful dish featuring succulent lamb marinated in aromatic spices and cooked to perfection.\n",
            "- Imperial Biryani: A fragrant rice dish layered with tender chicken, basmati rice, aromatic spices, and saffron.\n",
            "- Jewel of the Palace: An exquisite vegetarian platter with a variety of colorful and flavorful dishes, including paneer tikka, vegetable korma, and raita.\n",
            "\n",
            "**The Maharajah's Table**\n",
            "- Maharaja's Thali: A grand feast featuring an array of traditional dishes, including rice, lentils, curries, and breads.\n",
            "- Royal Rogan Josh: A classic lamb dish cooked in a rich and flavorful tomato-based sauce.\n",
            "- Nizam's Kebab: A succulent skewer of marinated lamb grilled to perfection.\n",
            "\n",
            "**Indra's Nectar**\n",
            "- Mango Lassi: A refreshing blend of sweet mangoes, yogurt, and spices.\n",
            "- Saffron Chai: A fragrant and aromatic tea infused with saffron, cardamom, and ginger.\n",
            "- Rosewater Sharbat: A delicate and floral drink made from rose petals and sweetened with sugar.\n",
            "\n",
            "**Saffron and Star Anise**\n",
            "- Saffron Chicken Tikka: Tender chicken marinated in a saffron and star anise yogurt sauce and grilled to perfection.\n",
            "- Star Anise Biryani: A flavorful biryani with basmati rice infused with the warm and spicy aroma of star anise.\n",
            "- Saffron Kulfi: A traditional Indian ice cream flavored with saffron and pistachios.\n",
            "\n",
            "**The Jewel of India**\n",
            "- Paneer Butter Masala: A creamy and flavorful dish featuring soft paneer cheese in a rich tomato-based sauce.\n",
            "- Aloo Gobi: A classic vegetarian dish of potatoes and cauliflower cooked with aromatic spices.\n",
            "- Navratan Korma: A rich and luxurious curry made with nine vegetables and a creamy cashew nut sauce.\n",
            "\n",
            "**The Spice Merchant**\n",
            "- Chicken Tikka Masala: A popular dish featuring tender chicken cooked in a creamy and flavorful tomato-based sauce.\n",
            "- Tandoori Shrimp: Succulent shrimp marinated in aromatic spices and grilled in a clay oven.\n",
            "- Ginger Garlic Naan: A soft and flavorful bread topped with a savory mixture of ginger, garlic, and herbs.\n",
            "\n",
            "**The Tandoori Haven**\n",
            "- Tandoori Chicken: A signature dish of tender chicken marinated in a flavorful yogurt and spice blend and grilled in a clay oven.\n",
            "- Tandoori Paneer: Soft paneer cheese marinated in spices and grilled to perfection.\n",
            "- Chicken Tikka: Boneless chicken marinated in yogurt and spices and grilled on skewers.\n",
            "\n",
            "**The Mango Tree**\n",
            "- Mango Curry: A sweet and tangy curry featuring ripe mangoes cooked with spices and coconut milk.\n",
            "- Aam Panna: A refreshing drink made from raw mangoes, mint, and spices.\n",
            "- Mango Lassi: A creamy and sweet blend of mangoes, yogurt, and spices.\n",
            "\n",
            "**The Royal Pavilion**\n",
            "- Royal Thali: An elaborate feast with a variety of traditional dishes, including rice, lentils, curries, breads, and desserts.\n",
            "- Biryani Royale: A luxurious biryani with basmati rice, tender lamb, aromatic spices, and saffron.\n",
            "- Gulab Jamun: A sweet and syrupy dessert made from milk solids and deep-fried.\n",
            "\n",
            "**The Palace of Flavors**\n",
            "- Butter Chicken: A creamy and flavorful dish featuring tender chicken cooked in a tomato-based sauce.\n",
            "- Vegetable Biryani: A flavorful biryani with vegetables, basmati rice, and aromatic spices.\n",
            "- Raita: A refreshing yogurt-based dip served with curries and breads.\n"
          ]
        }
      ],
      "source": [
        "res = chain({\"cuisine\": \"indian\"})\n",
        "for key, val in res.items():\n",
        "  print(f\"{key} --> {val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4069a75e",
      "metadata": {
        "id": "4069a75e"
      },
      "source": [
        "##**06. Agents and Tools**\n",
        "\n",
        "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
        "\n",
        "\n",
        "When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n",
        "\n",
        "- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
        "- LLM: The language model powering the agent.\n",
        "- Agent: The agent to use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z-4QjS31LD_s",
      "metadata": {
        "id": "Z-4QjS31LD_s"
      },
      "source": [
        "Agent is a very powerful concept in LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GgNLQ6kSL4na",
      "metadata": {
        "id": "GgNLQ6kSL4na"
      },
      "source": [
        "For example I have to travel from Dubai to Canada, I type this in ChatGPT\n",
        "\n",
        "\n",
        "\n",
        "---> Give me  two flight options from Dubai to Canada on September 1, 2024 | ChatGPT will not be able to answer because has knowledge till\n",
        "September 2021\n",
        "\n",
        "\n",
        "\n",
        "ChatGPT plus has Expedia Plugin, if we enable this plugin it will go to Expedia Plugin and will try to pull information about Flights & it will show the information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tkzApnDnJy8p",
      "metadata": {
        "id": "tkzApnDnJy8p"
      },
      "source": [
        "SerpApi is a real-time API to access Google search results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09cd3a12",
      "metadata": {
        "id": "09cd3a12"
      },
      "source": [
        "#### Wikipedia and llm-math tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "TpJ3gA4YZKMx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpJ3gA4YZKMx",
        "outputId": "86beab4c-c32c-4feb-8559-f03f32b51e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=c0abe7746ebb95201ad733c6016953b397695fef52af14c23a79ba50122bbc0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "kb7ZpkpcVIYO",
      "metadata": {
        "id": "kb7ZpkpcVIYO"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "14d06ce6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "14d06ce6",
        "outputId": "eeb0249c-be23-4b3c-b53e-fe0e1bdc1a09",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: GDP of US in 2024\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of U.S. states and territories by GDP\n",
            "Summary: This is a list of U.S. states and territories by gross domestic product (GDP). This article presents the 50 U.S. states and the District of Columbia and their nominal GDP at current prices.\n",
            "The data source for the list is the Bureau of Economic Analysis (BEA) in 2024. The BEA defined GDP by state as \"the sum of value added from all industries in the state.\"\n",
            "Nominal GDP does not take into account differences in the cost of living in different countries, and the results can vary greatly from one year to another based on fluctuations in the exchange rates of the country's currency. Such fluctuations may change a country's ranking from one year to the next, even though they often make little or no difference in the standard of living of its population.\n",
            "Overall, in the calendar year 2024, the United States' Nominal GDP at Current Prices totaled at $29.017 trillion, as compared to $25.744 trillion in 2022.\n",
            "The three U.S. states with the highest GDPs were California ($4.080 trillion), Texas ($2.695 trillion), and New York ($2.284 trillion). The three U.S. states with the lowest GDPs were Vermont ($45.4 billion), Wyoming ($53.0 billion), and Alaska ($69.8 billion).\n",
            "GDP per capita also varied widely throughout the United States in 2024, with New York ($117,332), Massachusetts ($110,561), and Washington (state) ($108,468) recording the three highest GDP per capita figures in the U.S., while Mississippi ($53,061), Arkansas ($60,276), and West Virginia ($60,783) recorded the three lowest GDP per capita figures in the U.S. The District of Columbia, though, recorded a GDP per capita figure far higher than any U.S. state in 2024 at $263,220.\n",
            "\n",
            "\n",
            "\n",
            "Page: List of countries by GDP (nominal) per capita\n",
            "Summary: This is a list of countries by nominal GDP per capita.\n",
            "GDP per capita is often considered an indicator of a country's standard of living; however, this is inaccurate because GDP per capita is not a measure of personal income. Measures of personal income include average wage, real income, median income, disposable income and GNI per capita.\n",
            "Comparisons of GDP per capita are also frequently made on the basis of purchasing power parity (PPP), to adjust for differences in the cost of living in different countries, see List of countries by GDP (PPP) per capita. PPP largely removes the exchange rate problem but not others; it does not reflect the value of economic output in international trade, and it also requires more estimation than GDP per capita. On the whole, PPP per capita figures are more narrowly spread than nominal GDP per capita figures.\n",
            "The figures presented here do not take into account differences in the cost of living in different countries, and the results vary greatly from one year to another based on fluctuations in the exchange rates of the country's currency. Such fluctuations change a country's ranking from one year to the next, even though they often make little or no difference to the standard of living of its population.\n",
            "For change of GDP per capita over time as a measure of economic growth, see real GDP growth and real GDP per capita growth.\n",
            "Non-sovereign entities (the world, continents, and some dependent territories) and states with limited international recognition are included in the list in cases in which they appear in the sources. These economies are not ranked in the charts here (except Kosovo and Taiwan), but are listed in sequence by GDP for comparison. In addition, non-sovereign entities are marked in italics. Four UN members (Cuba, Liechtenstein, Monaco and North Korea) do not belong to the International Monetary Fund (IMF), hence their economies are not ranked below. Kosovo, despite not being a member of the United Nations, is a member of IMF. Taiwan is not a IMF member but it is still listed in the official IMF indices.\n",
            "Several leading GDP-per-capita (nominal) jurisdictions may be considered tax havens, and their GDP data subject to material distortion\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe GDP of US in 2024 was $29.017 trillion\n",
            "Final Answer: 29.017 trillion\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'29.017 trillion'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# install this package: pip install wikipedia\n",
        "\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Let's test it out!\n",
        "\n",
        "\n",
        "agent.run(\"What was the GDP of US in 2024?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6be7ee7",
      "metadata": {
        "id": "b6be7ee7"
      },
      "source": [
        "##**07: Memory**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-WkJqQzRZaXL",
      "metadata": {
        "id": "-WkJqQzRZaXL"
      },
      "source": [
        "Chatbot application like ChatGPT, you will notice that it remember past information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "NE-poGM1Zxss",
      "metadata": {
        "id": "NE-poGM1Zxss"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "2acab5d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2acab5d0",
        "outputId": "fab41110-7c50-4637-cabb-a76f3eb094ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest a fency name for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "* **El Paladar de Oro:** The Golden Palate\n",
            "* **Casa de los Sabores Auténticos:** House of Authentic Flavors\n",
            "* **Hacienda de la Comida Celebrada:** Hacienda of Celebrated Food\n",
            "* **La Mesa Exquisita:** The Exquisite Table\n",
            "* **El Cenáculo de la Cocina Mexicana:** The Supper Room of Mexican Cuisine\n",
            "* **Altar de los Sabores:** Altar of Flavors\n",
            "* **Cozumel de los Sabores:** Cozumel of Flavors\n",
            "* **Tulum de la Gastronomía:** Tulum of Gastronomy\n",
            "* **Xcaret de la Deliciosa Comida:** Xcaret of Delicious Food\n",
            "* **Chichén Itzá de los Manjares:** Chichén Itzá of Delicacies\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm,prompt=prompt_template_name, verbose=True)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "5bc200f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bc200f9",
        "outputId": "e8484ca9-407d-4977-bf9d-5ba147222c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Indian food. Suggest a fency name for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "* **Saffron & Jewel**\n",
            "* **The Golden Peacock**\n",
            "* **Celestial Spice**\n",
            "* **Amaya: Abode of Aromas**\n",
            "* **Indra's Elixir**\n",
            "* **Nirvana: Symphony of Flavors**\n",
            "* **Taj Mahal: Gateway to Culinary Delights**\n",
            "* **Divine Curry**\n",
            "* **The Saffron Palace**\n",
            "* **Apsara: The Heavenly Banquet**\n",
            "* **Parampara: Heritage of Taste**\n",
            "* **Rasa: Essence of Indian Cuisine**\n",
            "* **Masala Mantra: The Culinary Invocation**\n",
            "* **Tulsi: The Holy Spice**\n",
            "* **Amrit: Elixir of Spice**\n"
          ]
        }
      ],
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "229a6888",
      "metadata": {
        "id": "229a6888"
      },
      "outputs": [],
      "source": [
        "chain.memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "f492fb5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f492fb5a",
        "outputId": "0892e25c-3811-4a54-a5d3-f8976ce0186c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "type(chain.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "871492be",
      "metadata": {
        "id": "871492be"
      },
      "source": [
        "##**ConversationBufferMemory**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coQKpk8jZ8zz",
      "metadata": {
        "id": "coQKpk8jZ8zz"
      },
      "source": [
        "We can attach memory to remember all previous conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "53eea298",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53eea298",
        "outputId": "a2320596-bc56-4f96-b019-9682b0167736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-5d2479adeed0>:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* **El Sol Dorado** (The Golden Sun)\n",
            "* **La Hacienda del Sol** (The Hacienda of the Sun)\n",
            "* **Castillo de los Sabores** (Castle of Flavors)\n",
            "* **El Palacio de los Tacos** (The Palace of Tacos)\n",
            "* **La Fiesta de los Mariachis** (The Fiesta of the Mariachis)\n",
            "* **La Casa de la Abuela** (Grandmother's House)\n",
            "* **El Rancho de la Alegría** (The Ranch of Happiness)\n",
            "* **La Cantina del Cielo** (The Tavern of Heaven)\n",
            "* **El Paraíso de las Enchiladas** (The Paradise of Enchiladas)\n",
            "* **El Imperio de la Cocina Mexicana** (The Empire of Mexican Cuisine)\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "0de5d50b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0de5d50b",
        "outputId": "d04867bb-9dc0-4537-ebcb-14152bb6cae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* **Al Shams Al Dhahabiyyah** (The Golden Sun)\n",
            "* **Al Qamar Al Muzaffer** (The Triumphant Moon)\n",
            "* **Al Bustan Al Shahi** (The Royal Garden)\n",
            "* **Dar Al Bint Al Sultan** (The House of the Sultan's Daughter)\n",
            "* **Al Riyad Al Janniyyah** (The Gardens of Paradise)\n",
            "* **Al Majid Al Mua'zzam** (The Mighty Exalted)\n",
            "* **Al Rahma Al Wafirah** (The Abundant Mercy)\n",
            "* **Al Noor Al Mutamayyiz** (The Distinguished Light)\n",
            "* **Al Sahel Al Anwar** (The Luminous Coast)\n",
            "* **Minhaj Al Sultan** (The Sultan's Way)\n",
            "* **Al Wasilah Al Fakhra** (The Honorable Link)\n",
            "* **Al Qusayr Al Zahra** (The Blooming Palace)\n",
            "* **Al Maqam Al Shamikh** (The Lofty Station)\n",
            "* **Al Muqam Al A'la** (The Supreme Position)\n"
          ]
        }
      ],
      "source": [
        "name = chain.run(\"Arabic\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "5cc88888",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cc88888",
        "outputId": "309e4d6d-5abd-45e7-a427-2534a3af1cb8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Mexican\n",
            "AI: * **El Sol Dorado** (The Golden Sun)\n",
            "* **La Hacienda del Sol** (The Hacienda of the Sun)\n",
            "* **Castillo de los Sabores** (Castle of Flavors)\n",
            "* **El Palacio de los Tacos** (The Palace of Tacos)\n",
            "* **La Fiesta de los Mariachis** (The Fiesta of the Mariachis)\n",
            "* **La Casa de la Abuela** (Grandmother's House)\n",
            "* **El Rancho de la Alegría** (The Ranch of Happiness)\n",
            "* **La Cantina del Cielo** (The Tavern of Heaven)\n",
            "* **El Paraíso de las Enchiladas** (The Paradise of Enchiladas)\n",
            "* **El Imperio de la Cocina Mexicana** (The Empire of Mexican Cuisine)\n",
            "Human: Arabic\n",
            "AI: * **Al Shams Al Dhahabiyyah** (The Golden Sun)\n",
            "* **Al Qamar Al Muzaffer** (The Triumphant Moon)\n",
            "* **Al Bustan Al Shahi** (The Royal Garden)\n",
            "* **Dar Al Bint Al Sultan** (The House of the Sultan's Daughter)\n",
            "* **Al Riyad Al Janniyyah** (The Gardens of Paradise)\n",
            "* **Al Majid Al Mua'zzam** (The Mighty Exalted)\n",
            "* **Al Rahma Al Wafirah** (The Abundant Mercy)\n",
            "* **Al Noor Al Mutamayyiz** (The Distinguished Light)\n",
            "* **Al Sahel Al Anwar** (The Luminous Coast)\n",
            "* **Minhaj Al Sultan** (The Sultan's Way)\n",
            "* **Al Wasilah Al Fakhra** (The Honorable Link)\n",
            "* **Al Qusayr Al Zahra** (The Blooming Palace)\n",
            "* **Al Maqam Al Shamikh** (The Lofty Station)\n",
            "* **Al Muqam Al A'la** (The Supreme Position)\n"
          ]
        }
      ],
      "source": [
        "print(chain.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a88b5b",
      "metadata": {
        "id": "a0a88b5b"
      },
      "source": [
        "##**ConversationChain**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FyFmOOemaVxb",
      "metadata": {
        "id": "FyFmOOemaVxb"
      },
      "source": [
        "Conversation buffer memory goes growing endlessly\n",
        "\n",
        "Just remember last 5 Conversation Chain\n",
        "\n",
        "Just remember last 10-20 Conversation Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "687ddd2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "687ddd2f",
        "outputId": "04922e9b-abce-44ce-f9c1-dc0b6d9a9ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-bb6684f844b9>:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  convo = ConversationChain(llm=llm)\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "convo = ConversationChain(llm=llm)\n",
        "print(convo.prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "47ad5062",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "47ad5062",
        "outputId": "1445b645-ec5f-4bcc-bd2d-b5c6ddec902b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'West Indies'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "convo.run(\"Who won the first cricket world cup?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "03c80b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "03c80b54",
        "outputId": "93be9b4e-6c40-4ca7-adfa-78a2ba0b0105"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "07342f88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "07342f88",
        "outputId": "09f3ede0-a504-4db0-c722-52546a55ae67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Frank Worrell'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "4e459d07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e459d07",
        "outputId": "93303912-b015-4ce6-a38a-92a58bfc55f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI: West Indies\n",
            "Human: How much is 5+5?\n",
            "AI: 10\n",
            "Human: Who was the captain of the winning team?\n",
            "AI: Frank Worrell\n"
          ]
        }
      ],
      "source": [
        "print(convo.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feaa3abd",
      "metadata": {
        "id": "feaa3abd"
      },
      "source": [
        "##**ConversationBufferWindowMemory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "460eb33c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "460eb33c",
        "outputId": "6367ad13-4a1f-465f-ab13-6f6e6aecca43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-c44103b4dc92>:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferWindowMemory(k=3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'West Indies.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=3) # k is no of last chat\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who won the first cricket world cup?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "d395beaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d395beaf",
        "outputId": "65bbfff6-9def-4adb-91e6-3ba086d77c21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "93b24745",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "93b24745",
        "outputId": "12f9edaa-c9df-4385-96a4-ea387c61c4e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Frank Worrell.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "K63Ie5FTvjzo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K63Ie5FTvjzo",
        "outputId": "f131ba6f-8c27-49ad-c051-353d43f220f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI: West Indies.\n",
            "Human: How much is 5+5?\n",
            "AI: 10.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI: Frank Worrell.\n"
          ]
        }
      ],
      "source": [
        "print(convo.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mkFhYXKUmnDO",
      "metadata": {
        "id": "mkFhYXKUmnDO"
      },
      "source": [
        "#**08: Document Loaders**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "-9WXxhHCZtTn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9WXxhHCZtTn",
        "outputId": "28f57854-96ab-4299-cb0c-33bba34901b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "wqlRJc7DmtwA",
      "metadata": {
        "id": "wqlRJc7DmtwA"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "# from langchain.document_loaders import PyPDFDirectoryLoader # for directory loading\n",
        "\n",
        "loader = PyPDFLoader(\"/content/TOC.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "XGTtdS26mt0_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGTtdS26mt0_",
        "outputId": "98d87929-14f3-4493-c690-52083392b322",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/TOC.pdf', 'page': 0}, page_content=' \\nSCHOOL OF COMPUTING \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\n \\n \\n \\n  \\n \\n \\n \\n \\nUNIT – I – THEORY OF COMPUTATION – SCSA1302 '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 1}, page_content='1 \\n \\nSYLLABUS \\nIntroduction - Regular Languages and Regular Expressions - Deterministic Finite Automata -  \\nNon-Deterministic Finite Automata - NFA to DFA Conversion – NFA NULL Construction - \\nNFA NULL to NFA Conversion - Kleene’s Theorem Part I & II. \\n1. Introduction \\n1.1.What is Theory of Computation or Automata Theory? \\n• Theory of Computation is how efficiently problems can be solved on a model of \\ncomputation, using an algorithm. \\n• It is mainly about what kind of things can you really compute mechanically, how fa st \\nand how much space does it take to complete the task. \\n• Ex1: To design a machine that accepts all binary strings ends in 0 and reject all other \\nthat does not ends in 0. \\n                11011010 – Accept \\n• Ex2: To design a machine to accepts all valid ‘C’ codes \\n Machine will check the binary equivalent of this code and from this binary equivalent \\nit tells weather it is valid piece of C code or invalid. \\n     Question  : Is it possible to design a machine? \\n      Yes – The best example is Compiler. \\n• Ex3: To design a machine that accepts all valid ‘C’ codes and never goes into infinite. \\n  Question  : Is it possible to design a machine? \\n    No \\n \\n \\n \\nFigure 1.1. Model of a TOC \\n \\n \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 2}, page_content='2 \\n \\n \\nTable 1.1 Modelling Languages and Language Acceptor \\n \\nLAYERS AND LEVELS IN THEORY OF COMPUTATION: \\n• FSM – Finite State Machine – Simplest model of Computation and it has very  limited \\nmemory. \\n     Perform low level computation and calculations \\n• CFL – Context Free Language \\n    Performs   some higher level of computation. \\n• Turing Machine – Much powerful model perform very high level computation designed \\nby Alan Turing in 1940. \\n• Undecidable – Problem cannot be solved mechanically is falls under undecidable layer. \\n1.2 Basic Units of Regular Language: \\nAlphabets (∑ ) : { a, b} or {0,1} \\nString( w)         : Collection of input alphabets \\nLanguage (L)    : Collection of Strings \\nEmpty Set        : Ø \\nNULL String     : ε or λ \\n1.3. Finding Language using Conditions: \\n1. Find L with 0’S and 1’s with odd no. of 1’s \\n∑ ={ 0,1} \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 3}, page_content='3 \\n \\nw ={ 1,01,10,100,010, 111,1011……..} \\nw ={ 1,01,10,100,010, 110 ,111,1011……..} --invalid \\nL  = {w/w consists of odd no. of 1’s} \\n2. Find L with 0’s and 1’s with even no. of 1’s \\n∑ ={ 0,1} \\nw ={Λ  ,11,011,101,110,0110, 1010,  ……..} \\nw ={Λ  ,11,011,101,100, 110,0110, 1010,  …..} --invalid \\nL  = {w/w consists of even no. of 1’s} \\n3. Find L with a’s and b’s with even no. of a’s \\n∑ ={ a,b} \\nw ={Λ  ,aa,baa,aba,aab,baab, abba,abab  ……..} \\nw ={Λ ,aa,baa,aaa,aab,baab, abba,abab  ……..} --invalid \\nL  = {w/w consists of even no. of a’s} \\n4. Find L with a’s and b’s with even no of a’s and b’s. \\n∑ ={ a,b} \\nw ={Λ  ,aa,bb,aabb,abab,baba,bbaa ……..} \\nL  = {w/w consists of even no. of a’s and b’s} \\n5. Find L with a’s and b’s having a substring aa \\n∑ ={ a,b} \\nw ={aa,baa,aab,baab, abaa,aabaa  ……..} \\nL  = {w/w consists of a substring aa} \\n1.4. Regular Language: \\n• A language is regular if there exits a DFA for that language. \\n• The language accepted by DFA is RL.  \\n1.5. Regular Expression: \\n• A Mathematical notation used to describe the regular language.  \\n• This is formed by using 3 Symbols:  \\n(i). [dot operator] – for concatenation  \\n(ii) + [Union operator] –at least 1 occurrence  \\n      eg) 1+ = {1,11,111,-------} \\n(iii) {*} [Closure Operator ] – Zero or more occurrences  \\n     eg) 1* = {Λ ,1,11,111,…..} '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 4}, page_content='4 \\n \\n1.6 Basic Regular Expressions: \\n• Ø is a RE and denotes the empty set.  \\n• ε  is a RE and denotes the set { ε }  \\n• For each a in ∑, a is a RE and denotes the set {a}  \\n• If r and s are RE that denoting the languages R and S respectively, then,  \\n– (r+s) is a RE that denotes the set (RUS)  \\n– (r.s) is a RE that denotes the set R.S \\n–  (r)* is a RE that denotes the set R*  \\n1.7 Problems on RE: \\n1. Write the RE for the language of even no. of 1’s. \\n∑={0,1} \\nW={ᴧ,11,011,101,110,1111,1100,....} \\nRE=(11)* \\n2. Write the RE for the language of odd no. of 1’s. \\n∑={0,1} \\nW={1,10,01,100,111,1110,.....} \\nRE=(11)*.1 \\n3. Write the RE for the language of any length including Ʌ.(a,b) \\n∑={a,b} \\nW={ᴧ,a,b,aa,ab,aab,baa,aaaa,.....} \\nRE=(a+b)* \\n4. Write the RE with a string starting with a. \\n∑={a,b} \\nW={a,aa,ab,aaa,abb,.....} \\nRE=(a).(a+b)* \\n5. Write the RE for the language having a substring aa. \\n∑={a,b} \\nW={aa,baa,aab,baaa,aaaa....} \\nRE=(a+b)*.aa.(a+b)* \\n6. Write the RE with a string starting with either a or ab. \\n∑={a,b} '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 5}, page_content='5 \\n \\nW={a,ab,aa,aba,abb,abbb,....} \\nRE=(a+ab).(a+b)* \\n7. Write RE with a string consists of a’s and b’s ending with abb. \\n∑={a,b} \\nW={abb,aabb,babb,aaabb,......} \\nRE=(a+b)*.abb \\n8. Write RE with a string consists of a’s and b’s starting with abb. \\n∑={a,b} \\nW={abb,abbb,abba,abbaa,.....} \\nRE=abb.(a+b)* \\n9. Write the  RE for identifiers in ‘C’ Programming. \\nLetter=(a-z) \\nDigit=(0-9) \\nRE=(letter+_).(letter+_+digit)* \\n10. Write the RE with a string that should not start with two 0’s. \\n∑={0,1} \\nW={0,1,01,011,110,....} \\nRE=(01+1).(1+0)* \\n11. Write  RE with a string that begins and ends with double consecutive letters. \\n∑={a,b} \\nW={aa,bb,aabb,bbaa,aabaa,bbbaa,......} \\nRE=(aa+bb).(a+b)*.(aa+bb) \\n12. Strings of a’s and b’s  in which 3rd symbol from right end is ‘a’. \\n∑={a,b} \\nW={aaa,abb,aabb,bbabb,…} \\nRE=(a+b)*a.(a+b)(a+b) \\n13. Write RE for the strings consisting of atleast 1 ‘a’ followed by strings consisting of \\natleast 1 ‘b’ followed by strings consisting of atleast 1 ‘c’.  \\n∑={a,b,c} \\nW={abc,aabc,abbc,aabbcc,aaabbc,…} \\nRE=a+.b+.c+ '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 6}, page_content='6 \\n \\n \\n14. Write the RE for the strings over {0,1} of length 6 or less. \\n∑={0,1} \\nLength 6-{001100,110011,010101,000000,..} \\n(0+1).(0+1).(0+1).(0+1).(0+1).(0+1) \\n(0+1+Ʌ)6 \\n(0+1)6 \\n(0+1+Ʌ)* \\n15. Write RE for the string(a,b) whose length divisible by 3. \\n∑={a,b} \\nW={Ʌ,aaa,aba,abb,aab,aabbaa,….} \\nRE=(aaa+aab+aba+baa+bbb+baa+abb+bab)* \\n1.8 What is Finite Automata? \\n• Simplest model of a computing device. \\n• Finite automata are used to recognize patterns. \\n• A machine that accepts Regular Language. \\n• It takes the string of symbol as input and changes its state accordingly. When the desired \\nsymbol is found, then the transition occurs. \\n• At the time of transition, the automata can either move to the next state or stay in the \\nsame state. \\n• Finite automata have two states, Accept state or Reject state. When the input string is \\nprocessed successfully, and the automata reached its final state, then it will accept. \\n    Applications: \\n– Compilers \\n– Text processing \\n– Hardware design. \\nTypes of Automata: \\n '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 7}, page_content='7 \\n \\n \\nFigure 1.2 Types of Automata \\n \\nFigure 1.3  Difference between DFA and NFA \\n \\n2. DFA (Deterministic Finite Automata): \\n \\n• Only one path for specific input from the current state to the next state. \\n• DFA does not accept the null move. \\n• It is used in Lexical Analysis phase in Compilers. \\nExample: RE=(a+b)+ \\n \\nFigure 1.4 Sample DFA \\nDefinition of DFA: \\nA finite automaton is a collection of 5-tuple (Q, ∑, δ, q0, F), where: \\nQ: finite set of states   \\n∑: finite set of the input symbol   \\nq0: initial state    \\nF: final state   \\nδ: Transition function   \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 8}, page_content='8 \\n \\n2.2 Construction of DFA: \\n1. Construct DFA to accept strings of a’s and b’s having a substring aa. \\nW={aa,aaa,baa,aab,aabb,abaa…..} \\n \\n \\nFigure 1.5 State Diagram \\nDFA Definition \\nM=(Q, ∑,q0, δ,A) \\nQ={q0,q1,q2} \\n∑={a,b} \\n q0 =q0 \\nA = q2 \\nδ –Transition Function \\nδ(q0,a)=q1 \\nδ(q0,b)=q0 \\nδ(q1,a)=q2 \\nδ(q1,b)=q0 \\nδ(q2,a)=q2 \\nδ(q2,b)=q2 \\n2. Construct DFA to accept string of a’s and b’s having exactly 1 ‘a’. \\nW={a,ab,ba,bba,abb,bbba,….} \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 9}, page_content='9 \\n \\n \\nFigure 1.6 State Diagram \\nDFA Definition \\nM=(Q, ∑,q0, δ,A) \\nQ={q0,q1} \\n∑={a,b} \\nq0 =q0 \\nA = q1 \\nδ –Transition Function \\nδ(q0,a)=q1 \\nδ(q0,b)=q0 \\nδ(q1,a)=null \\nδ(q1,b)=q1 \\n \\n3. Construct DFA to accept strings of a’s and b’s with atleast 1 ‘a’. \\nW={a,aa,ab,ba,bba,baa,….} \\n \\nFigure 1.7 State Diagram \\nDFA Definition \\nM=(Q, ∑,q0, δ,A) \\nQ={q0,q1} \\n∑={a,b} \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 10}, page_content=\"10 \\n \\nq0 =q0 \\nA = q1 \\nδ –Transition Function \\nδ(q0,a)=q1 \\nδ(q0,b)=q0 \\nδ(q1,a)=q1 \\nδ(q1,b)=q1 \\n \\n4. Construct DFA to accept strings of 0’s and 1’s with substring 01. \\nW={01,001,010,011,1001,…..} \\n \\nFigure 1.8 State Diagram \\nDFA Definition: \\nM=(Q, ∑,q0, δ,A) \\nQ={q0,q1,q2} \\n∑={0,1} \\nq0 =q0 \\nA = q2 \\nδ –Transition Function \\nδ(q0,0)=q1 \\nδ(q0,1)=q0 \\nδ(q1,0)=q1 \\nδ(q1,1)=q2 \\nδ(q2,0)=q2 \\nδ(q2,1)=q2 \\n5. Construct DFA to accept strings of a’s and b' not more than 3 ’a’. \\nW={Ʌ,a,aa,aaa,aba,abb,bbb,aabb,…..} \\n\"),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 11}, page_content='11 \\n \\n \\n \\nFigure 1.9 State Diagram \\nDFA Definition \\nM=(Q, ∑,q0, δ, A) \\nQ={q0,q1,q2,q3} \\n∑={a,b} \\nq0 =q0 \\nA = {q0,q1,q2,q3} \\nδ –Transition Function \\nδ(q0,a)=q1 \\nδ(q0,b)=q0 \\nδ(q1,a)=q2 \\nδ(q1,b)=q1 \\nδ(q2,a)=q3 \\nδ(q2,b)=q2 \\nδ(q3,a)=null \\nδ(q3,b)=q3 \\n6. Construct DFA to accept strings that end with 011. \\nW={011,1011,0011,11011,00011,100011…..}001000011,01100011, \\n \\nFigure 1.10 State Diagram \\nDFA Definition \\nM=(Q, ∑,q0, δ, A) \\nQ={q0,q1,q2,q3} \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 12}, page_content='12 \\n \\n∑={0,1} \\nq0 =q0 \\nA = q3 \\nδ –Transition Function \\nδ(q0,0)=q1 \\nδ(q0,1)=q0 \\nδ(q1,0)=q1 \\nδ(q1,1)=q2 \\nδ(q2,0)=q1 \\nδ(q2,1)=q3 \\nδ(q3,0)=q1 \\nδ(q3,1)=q0 \\n \\n7. Construct DFA to accept strings of a’s and b’s with even number of a’s and b’s. \\nW={Ʌ,aa,bb,aabb,abab,baba,aaaabb…} \\n \\n8. Construct DFA with even number of a’s and odd no. of b’s. \\nW={b,aab,aba,baa,ababb,aaaab,aababab,….} \\n \\nM=(Q, ∑,q0, δ, A) \\n9. Construct DFA with odd number of a’s and even no. of b’s. \\nW={a,abb,bba,bab,abbaa,ababa,…..} \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 13}, page_content='13 \\n \\n \\nM=(Q, ∑,q0, δ, A) \\n10. Construct DFA with odd number of a’s and b’s. \\nW={ab,ba,babb,ababab,…….} \\n \\nM=(Q, ∑,q0, δ, A) \\n11. Construct DFA to accept odd and even no’s represented using binary notation. \\n0->0 \\n1->1 \\n2->10 \\n3->11 \\n4->100 \\n5->101 \\n6->110 \\n7->111 \\n8->1000 \\n010 \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 14}, page_content='14 \\n \\n \\nFigure 1.11.State Diagram \\n  M=(Q, ∑,q0, δ, A) \\n2.2 Extension of  δ:  δ* \\nδ-> for one input symbol \\n δ=Q x ∑ -> Q \\nδ*->the state in which FA ends up if it begins in state q and receives a string x of input \\nsymbols \\n            δ*(q,x)   i.e.  δ*: Q x ∑*->Q \\n \\nRecursive Definition of δ*: \\nLet M=(Q, ∑, q0, A , δ) be finite automata, we define the function δ*: Q x ∑*->Q as follows: \\n(i) for any qϵQ,  δ*(q,ꓥ)=q \\n(ii) for any y ϵ∑*, a ϵ∑ and q ϵQ \\n      δ*(q,ya) = δ( δ*(q,y), a) \\nFor strings of of length 1, δ and δ* can be used interchangeably. \\nPROBLEMS: \\nFind  δ*(q0,abc) \\n \\nFigure 1.12 State Diagram \\nSolution : \\nδ*(q,ꓥ)=q \\nδ*(q,ya) = δ( δ*(q,y), a) \\nꓥa=aꓥ=a \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 15}, page_content=\"15 \\n \\nδ*(q0,abc) = δ(δ*(q0,ab),c) \\n= δ(δ(δ*(q0,a),b),c) \\n= δ(δ(δ(δ*(q0,Ʌ),a),b),c) \\n= δ(δ δ(q0,a),b),c) \\n= δ(δ(q1,b),c) \\n= δ(q2,c) \\n =q3 \\n2.4 STRING ACCEPTANCE BY FINITE AUTOMATA: \\nLet M=(Q,∑,q0,A, δ) be an FA. A string xε∑* is accepted by M, if \\nδ*( q0,x)ϵA \\n \\n2.5 LANGUAGE ACCEPTANCE BY FINITE AUTOMATA BY FINITE AUTOMATA: \\nThe language is accepted by M or the language recognized by M is the set, \\nL(M)= {x | x ϵ ∑* and δ*( q0,x)ϵA} \\n \\n3.NON-DETERMINISTIC FINITE AUTOMATA: \\n \\nFigure 1.13 NFA \\n• When there exist many paths for specific input from the current state to the next state. \\n• Every NFA is not DFA, but each NFA can be translated into DFA. \\n•  Types  \\n(i) NFA without Λ \\n(ii) NFA with  Λ \\nAdvantages of NFA over DFA: \\n–  DFAs are faster but more complex. \\n–  Build a FA representing the language that is a union, intersection, concatenation \\netc. of two (or more) languages easily by using NFA's. \\nDefinition: \\nNFA has 5 tuples M=(Q,∑,q0,A,δ), where  \\nQ: finite set of states   \\n\"),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 16}, page_content='16 \\n \\n∑: finite set of the input symbol   \\nq0: initial state    \\nA: final state   \\nδ: Transition function   \\n           δ: Q x ∑ →2Q \\n3.1 Example: \\nObtain an NFA to accept the language L={ w| w ε ababn or aban} \\n \\n \\nFigure 1.4 NFA State Diagram \\nQ={q0,q1,q2,q3,q4,q5} \\n∑={a,b} \\nq0={q0} \\nA={q3,q3} \\nδ: \\nδ(q0,a)={q1,q4} \\nδ(q0,b)= ∅ \\nδ(q1,a)= ∅ \\nδ(q1,b)={q2} \\nδ(q2,a)={q3} \\nδ(q2,b)= ∅ \\nδ(q3,a)= ∅ \\nδ(q3,b)={q3} \\nδ(q4,a)= ∅ \\nδ(q4,b)={q5} \\nδ(q5,a)={q5} \\nδ(q5,b)= ∅ \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 17}, page_content='17 \\n \\n \\n3.2 Problem: convert NFA to DFA [Subset Construction Method] \\n \\nFigure 1.15 NFA State Diagram \\n \\nSolution: \\nMN=( QN,∑N,q0,AN,δN) be an NFA. \\nδN(q0,a)={q0,q1) \\nδN(q0,b)={q1) \\nδN(q1,a)= ∅ \\nδN(q1,b)={q2) \\nδN(q2,a)={q2) \\nδN(q2,b)={q2) \\nMD=( QD,∑D,q0,AD,δD) be an DFA. \\nStep 1: \\nStart state of NFA is the start state of DFA. \\nObtain the transitions from this state. \\nq0 is the start state. \\nδD (q0,a)=δN(q0,a) \\n=[q0,q1]----→A \\nδD (q0,b)=δN(q0,b) \\n=[q1]----→B \\n \\nStep: 2  Transition from A: \\nδD (A,a)= δN(A,a) \\n = δN([q0,q1],a)  \\n = δN(q0,a)U δN(q1,a) \\n ={q0,q1} U ∅ \\n =[q0,q1]------→A \\n \\nδD (A,b)= δN(A,b)                                                     \\nState a b \\nq0 A B \\nA   \\nB   '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 18}, page_content='18 \\n \\n = δN([q0,q1],b)  \\n = δN(q0,b) U δN(q1,b)  \\n ={q1}U{q2} \\n =[q1,q2]------→C \\n \\n \\n \\n \\nTransition from B: \\nδD (B,a)= δN(B,a) \\n = δN([q1],a)               \\n = δN(q1,a)       \\n =∅ \\n \\nδD (B,b)= δN(B,b) \\n = δN([q1],b) \\n = δN(q1,b) \\n ={q2}---→D \\n  \\n \\n \\n \\n \\nTransition from C: \\nδD (C,a)= δN(C,a) \\n = δN([q1,q2],a) \\n = δN(q1,a)U δN(q2,a) \\n =∅Uq2 \\n =[q2]------→D \\n \\nδD (C,b)= δN(C,b) \\n = δN([q1,q2],b) \\n = δN(q1,b) U δN(q2,b) \\n ={q2}Uq2 \\nState a b \\nq0 A B \\nA A C \\nB   \\nC   \\nState a b \\nq0 A B \\nA A C \\nB ∅ D \\nC   \\nD   '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 19}, page_content='19 \\n \\n =[q2]------→D \\n \\n \\n \\n \\n \\n \\n \\nTransition from D: \\nδD (D,a)= δN(D,a) \\n = δN([q2],a) \\n = δN(q2,a) \\n =[q2]------→D \\nδD (D,b)= δN(D,b) \\n = δN([q2],b) \\n = δN(q2,b) \\n =q2---→D \\n \\n \\n \\n \\n \\n \\n \\nStep: 3 construct the DFA \\n \\n \\nFigure 1.16 State Diagram \\nState a b \\nq0 A B \\nA A C \\nB ∅ D \\nC D D \\nD   \\nState a b \\nq0 A B \\nA A C \\nB ∅ D \\nC D D \\nD D D '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 20}, page_content='20 \\n \\nThe final state q2 of NFA is there in C and D states in DFA. So make C and D as final state. \\n \\n3.3 STRING ACCEPTANCE BY AN NFA: \\nLet M=(Q,∑,q0,A,δ) be an NFA, the string xε∑* is accepted by M, if  \\nδ *(q0,x) ∩ A≠∅ \\n \\n3.4 LANGUAGE ACCEPTANCE BY A NFA: \\nThe language recognized or accepted by M is the set L(M) of all strings accepted by M. \\nL(M)={x| δ *(q0,x) ∩ A≠∅} \\n \\n3.5 Recursive definition of δ* for an NFA: \\nLet M=(Q,∑,q0,A,δ) be an NFA, the function δ*:Q x ∑*->2Q  is defined as follows. \\ni) For any qεQ, δ*(q,Ʌ)={q} \\nii) For any qεQ, yε∑* and aε∑, \\n           δ *(q,ya)=(⋃ )𝛿(𝑟,𝑎)\\n𝑟𝜀𝛿∗(𝑞,𝑦)  \\n \\n \\nFigure 1.17 State Diagram \\n Problems: \\nM=(Q,∑,q0,A,δ) \\n \\nFigure 1.18 State Diagram \\n \\nDetermine: \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 21}, page_content='21 \\n \\ni) δ*(q0,11)= (⋃ )𝜹(𝒓,𝟏)\\n𝒓𝜺𝜹∗(𝒒,𝟏)  \\n= ⋃ )𝜹(𝒓,𝟏)\\n𝒓𝜺{𝒒𝟎,𝒒𝟏}  \\n= δ(q0,1) U δ(q1,1) \\n={q0,q1} U {q2} \\n={q0,q1,q2} \\n∴11 is not accepted. \\nii) δ*(q0,01)= (⋃ )𝜹(𝒓,𝟏)\\n𝒓𝜺𝜹∗(𝒒,𝟎)  \\n    = ⋃ )𝜹(𝒓,𝟏)\\n𝒓𝜺{𝒒𝟎}  \\n                            = δ(q0,1)  \\n                       ={q0,q1} \\n∴01 is not accepted. \\niii) δ*(q0,111)= (⋃ )𝜹(𝒓,𝟏)\\n𝒓𝜺𝜹∗(𝒒,𝟏𝟏)  \\n      = ⋃ )𝜹(𝒓,𝟏)\\n𝒓𝜺{𝒒𝟎,𝒒𝟏,𝒒𝟐}  \\n                              = δ(q0,1) U δ(q1,1) U δ(q2,1) \\n      ={q0,q1} U{q2}U{q3}  \\n      ={q0,q1,q2,q3} \\n∴111 is  accepted. \\n \\niv) δ*(q0,011)= (⋃ )𝜹(𝒓,𝟏)\\n𝒓𝜺𝜹∗(𝒒,𝟎𝟏)  \\n     = ⋃ )𝜹(𝒓,𝟏)\\n𝒓𝜺{𝒒𝟎,𝒒𝟏}  \\n                             = δ(q0,1) U δ(q1,1) \\n     ={q0,q1} U{q2}  \\n     ={q0,q1,q2} \\n∴11 is not accepted. \\n3.6 THEOREM 1: \\nStatement:  \\nFor any NFA machine  M=(Q, ∑, q0, δ ,  A)  accepting a language L ⊆  ∑*, there  is a DFA \\nmachine M1= (Q, ∑, q0, δ ,  A) that accepts L. '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 22}, page_content='22 \\n \\n \\nProof by Structural Induction:     \\nProof: \\nDFA- M1is defined as follows: \\n– Q1=2Q \\n– q1=q0 \\n– A1={qϵQ1 |A⊆Q} \\n– For,qϵQ1 and aϵ∑, \\n \\n \\nTo prove, δ1*(q1,x)= δ*(q0,x) \\nM1accepts the same language as M. \\nProof by Structural Induction: \\n1.Basis Step \\nStrings of length 0 \\nIf x=ꓥ, \\n  LHS = δ1*(q1,x) = δ1*(q1,ꓥ) \\n           = q1------- (By definition of δ1*) \\n                      = {q0}  ------- (By definition of q1) \\n           = δ*(q0,ꓥ)------- (By definition of δ*) \\n                      = δ*(q0,x) = RHS \\n2.Induction Hypothesis:  \\nAssume the statement to be proved is true. \\nx is a string satisfying,  \\n \\n3.Induction Step:  \\nTo prove, for any aϵ∑, xϵ∑* \\n                           δ1*(q1,xa)= δ*(q0,xa)  to be proved \\n \\nLHS=δ1*(q1,xa)=δ1(δ1*(q1,x),a)    ------- (By definition of δ1*) \\n    = δ1(δ*(q0,x),a)  -------(By Induction Hypothesis) \\n    =   ⋃ )𝜹(𝒓,𝒂)\\n𝒓𝜺δ∗{𝒒𝟎,𝒙}  ------(By  1) \\n    =δ*(q0,xa) =RHS------- (By definition of δ*) \\nHence Proved.     \\n \\n4.NFA with Ʌ transition: \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 23}, page_content='23 \\n \\n• This allows transitions not only input symbols but also on null inputs. \\n• Ʌ or ε \\n• aɅ=a | oɅ=0 |1Ʌ = 1 \\no*    \\n \\n4.1 Definition:NFA-Ʌ \\nNFA-Ʌ is a 5 tuple machine M=(Q,∑,q0,A,δ), where  \\nQ -  is a set of finite states, \\n∑ - finite set of input symbols \\nq0εQ,  \\nA ⊆ Q and  \\nδ:Qx(∑U{Ʌ})->2Q \\n \\n4.2 Epsilon (NULL) Closure of a state -Λ(q): \\nΛ(q) is a set of states can be defined as follows: \\n• It is a set of all states that can be reached from any state on Λ symbol \\n• Let M=(Q, ∑, q0, δ ,  A) be a NFA- Λ machine and let S be any subset of Q. \\n• The Λ(S) is the set defined as follows: \\n 1. Every element of S is in element of Λ(S) \\n 2. For any q 𝞮 Λ(S), every element of δ(q, Λ) is in Λ(S) \\n4.3 Problems on Ʌ Closure: \\n1.  \\n \\nFigure 1.19 State Diagram \\n Ʌ(q0)={q0, q1, q2} \\nɅ(q1) ={q1, q0, q2} \\n       Ʌ(q2)={q2} \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 24}, page_content='24 \\n \\n2.  \\n \\n \\n \\nFigure 1.20 State Diagram \\n \\nɅ(q0)={q0, q1, q2} \\nɅ(q1) ={q0, q1, q2} \\nɅ(q2)={q2} \\n4.4. Extended Transition Function of NFA- Λ  (δ*): \\n• δ* \\n– Describes what happens when we start in  any state and follow any sequence of \\ninputs. \\n– Definition of δ*: \\n  Let M= (Q,Σ,δ,q0,A) be a NFA with Λ .  \\nWe define the function δ* : Q x ∑ * {Λ }→2Q  as follows: \\n 1. For any state q 𝞮 Q , δ* (q, Λ ) = Λ (q) \\n 2. for any state q 𝞮 Q , y 𝞮∑ *, a 𝞮 ∑ \\n   \\n                        δ*(q, ya)  = Ʌ(⋃ )𝛅(𝐫,𝐚)\\n𝒓𝜺𝛅∗ (𝐪,𝐲)  \\n \\nProblems on δ* for NFA-Ʌ \\n \\nFigure 1.21 State Diagram \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 25}, page_content='25 \\n \\n \\n(i) Find δ*(q0, Ʌ) \\n             δ*(q0, Ʌ) = Ʌ({q0}) \\n                   ={q0,p,t} \\n(ii) Find δ*(q0, 0)  \\n δ*(q0, Ʌ0) = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺𝛅∗ (𝐪𝟎,Ʌ)   \\n                   = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺{𝒒𝟎,𝒑,𝒕}  \\n                   = Ʌ(δ(q0,0) U δ(p,0)U δ(t,0)) \\n        = Ʌ(∅ U{P}U{u}) \\n        = Ʌ({p,u}) \\n        ={p,u}   \\nString not accepted. \\n(iii) δ*(q0, 01)  \\n δ*(q0, 01) = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺𝛅∗ (𝐪𝟎,𝟎)   \\n                  = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺{𝒑,𝒖}  \\n       = Ʌ(δ(p,1) U δ(u,1)) \\n      = Ʌ({r}U∅) \\n      = Ʌ({r}) \\n      ={r} \\nString not accepted. \\n(iv) δ*(q0, 010)  \\n δ*(q0, 010) = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺𝛅∗ (𝐪𝟎,𝟎𝟏)   \\n         = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺{𝒓}  \\n                    = Ʌ(δ(r,0))   \\n         = Ʌ({s}) \\n   ={s,u,q0,p,t} \\nString is accepted. \\n4.5 Conversion of NFA-Ʌ to an NFA: '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 26}, page_content='26 \\n \\n \\nFigure 1.21 State Diagram \\nɅ-closure(A)={A,B,D} \\nɅ-closure(B)={B,D} \\nɅ-closure(C)={C} \\nɅ-closure(D)={D} \\n(i) δ*(A,0)= δ*(A,Ʌ0) \\n                       =Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺𝛅∗ (𝐀,Ʌ)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓 𝜺 Ʌ(𝐀)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺 {𝑨,𝑩,𝑫}  \\n            =Ʌ(δ(A,0) U δ(B,0) U δ(D,0)) \\n            = Ʌ(A,C,D) \\n            ={A,B,C,D} \\n(ii) δ*(A,1)= δ*(A,Ʌ1) \\n                       =Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺𝛅∗ (𝐀,Ʌ)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓 𝜺 Ʌ(𝐀)  \\n             = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺 {𝑨,𝑩,𝑫}  \\n  =Ʌ(δ(A,1) U δ(B,1) U δ(D,1)) \\n             = Ʌ(∅) \\n   =∅ \\n(iii) δ*(B,0)= δ*(B,Ʌ0) \\n                       =Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺𝛅∗ (𝐁,Ʌ)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓 𝜺 Ʌ(𝐁)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺 {𝑩,𝑫}  \\n  =Ʌ(δ(B,0) U δ(D,0)) \\n  = Ʌ(C,D) \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 27}, page_content='27 \\n \\n   ={C,D} \\n(iv) δ*(B,1)= δ*(B,Ʌ1) \\n                       =Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺𝛅∗ (𝐁,Ʌ)  \\n           = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓 𝜺 Ʌ(𝐁)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺 {𝑩,𝑫}  \\n  =Ʌ(δ(B,1) U δ(D,1)) \\n  = Ʌ(∅) \\n   =∅ \\n(v) δ*(C,0)= δ*(C,Ʌ0) \\n                       =Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺𝛅∗ (𝐂,Ʌ)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓 𝜺 Ʌ(𝐂)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺 {𝑪}  \\n  =Ʌ(δ(C,0)) \\n   = Ʌ(∅) \\n    =∅ \\n(vi) δ*(C,1)= δ*(C,Ʌ1) \\n                       =Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺𝛅∗ (𝐂,Ʌ)  \\n  = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓 𝜺 Ʌ(𝐂)  \\n             = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺 {𝑪}  \\n             =Ʌ(δ(C,1)) \\n  = Ʌ(B) \\n  ={B,D} \\n    \\n(vii) δ*(D,0)= δ*(D,Ʌ0) \\n                       =Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺𝛅∗ (𝐃,Ʌ)  \\n      = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓 𝜺 Ʌ(𝐃)  \\n                 = Ʌ(⋃ )𝛅(𝐫,𝟎)\\n𝒓𝜺 {𝑫}  \\n       =Ʌ(δ(D,0)) \\n        = Ʌ(D) \\n       ={D} '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 28}, page_content='28 \\n \\n(viii) δ*(D,1)= δ*(D,Ʌ1) \\n                       =Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺𝛅∗ (𝐃,Ʌ)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓 𝜺 Ʌ(𝐃)  \\n            = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺 {𝑫}  \\n            =Ʌ(δ(D,1)) \\n            = Ʌ(∅) \\n  =∅ \\n \\nTransition Table: \\nNFA- Ʌ NFA \\nSTATES \\n∑ \\nδ*(q,0) δ*(q,1) \\nɅ 0 1 \\nA {B} {A} ∅ {A,B,C,D} ∅ \\nB {D} {C} ∅ {C,D} ∅ \\nC ∅ ∅ {B} ∅ {B,D} \\nD ∅ {D} ∅ {D} ∅ \\n \\nNFA: \\n \\n \\nFigure 1.22 State Diagram \\n \\nNote: Final state of NFA and NFA - Ʌ are same, moreover if initial state Ʌ(A)={A,B,D} has \\nNFA-Ʌ final state then initial state A is also final state. \\n4.6.Theorem 2 \\n• Equivalence of NFA-ꓥ and NFA \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 29}, page_content='29 \\n \\n• If L is accepted by an NFA with ꓥ transitions then L is accepted by NFA without ꓥ \\ntransitions \\n• Statement:  \\nFor any NFA NULL machine  M=(Q, ∑, q0, δ ,  A) accepting a language L ⊆  ∑*, there  \\nis a NFA machine M1= (Q, ∑, q0, δ ,  A) that accepts L. \\nGiven: \\nNFA-ꓥ,  M=(Q,∑,δ,q0,A) \\nNFA, M1=(Q1,∑,δ1,q1,A1) \\nProof:                                                             \\n• By Definitions: \\n \\n• For, aϵ∑ :     \\nδ1(q1,a) = Ʌ(⋃ )𝛅(𝐫,𝟏)\\n𝒓𝜺𝛅∗ (𝐂,Ʌ)    (By definition it is true if we pass a single length string) \\nTo Prove: δ1*(q1,x) = δ*(q0,x)  \\n     \\nProof: By Structural Induction \\nBasis Step: \\n             Take  |x|=0  =>  x= Ʌ \\nLHS: δ1*(q1, Ʌ) = {q1} \\n            RHS: : δ*(q0, Ʌ) = Ʌ {q} \\nSo the above statement is not true for |x|=ꓥ \\nHence we begin the induction with |x|=1 \\nLet, x=a \\nδ1*(q1, a) = δ*(q0, Ʌ)           (By definition it is true if we pass a single length string) \\n \\nInduction Hypothesis: Assumption: \\n x is a string satisfying:    δ1*(q1,x)= δ*(q0,x) \\nInduction Step \\n– To prove, for any aϵ∑, x ϵ∑* \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 30}, page_content='30 \\n \\n δ1*(q1,xa)= δ*(q0,xa) \\nLHS:   δ1*(q1,xa) \\n =⋃ )𝛅(𝐫,𝐚)\\n𝒓𝜺 δ1∗{𝒒𝟏,𝒙}    ----(By Induction Hypothesis) \\n             = ⋃ )𝛅𝟏(𝐫,𝐚)\\n𝒓𝜺 δ∗{𝒒𝟎,𝒙}     δ=δ1 if the length of the string   \\n          =⋃ )𝛅(𝐫,𝐚)\\n𝒓𝜺 δ∗{𝒒𝟎,𝒙}   \\n         =⋃ )𝛅(𝐫,𝐚)\\n𝒓𝜺 Ʌ(⋃ )𝛅(𝐬,Ʌ)\\n𝒔𝜺 δ∗{𝒒𝟎,𝒙}\\n \\n         = Ʌ(⋃ )𝛅(𝐬,𝐚)\\n𝒔𝜺 δ∗{𝒒𝟎,𝒙}  \\n                                                                 \\n       =  δ*(q, xa)                            \\n        =RHS  Hence the theorem is proved \\n \\n5.Kleen’s Theorem Part-I: \\nTheorem Statement: \\nAny RL can be accepted by a FA. \\nOr \\nLet ‘r’ be a RE, then there exists an NFA with Ʌ transitions that accepts L(r). \\nProof: \\nBy induction on the number of operators in the RE ‘r’ that there is an NFA ‘M’ with Ʌ -\\ntransitions having one final state, and no transitions out of this final state, such that L(M)=L(r). \\nBasis Step: ‘r’ has ∅ operators  \\n ‘r’ must be ∅, Ʌ or a where aℰ∑. \\nThe NFA for ‘r’ are \\n \\n      r=Φ                            r=Ʌ                            r=’a’ \\nInduction Hypothesis: \\nAssume that theorem is true for ‘r’ with fewer than ‘i’ operators, i>=1=>1<=n<i \\nInduction Step: \\nLet ‘r’ have ‘i’ operators. \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 31}, page_content='31 \\n \\nCase 1: r=r1+r2 \\n \\nFigure 5.1 State Diagram \\nLet NFA’s machine is M1=(Q1,∑1,δ1,q1,{f1}) & L(M1)=L(r1) \\nLet DFA’s machine is M2=(Q2,∑2,δ2,q2,{f2}) & L(M2)=L(r2) \\nWhere Q1 and Q2 are disjoint. \\n            q0->new initial state \\n      f0->new final state \\nConstruct M= (Q1UQ2U{q0,f0}, ∑1U∑2,δ,q0,{f0}) \\nWhere δ is defined by, \\ni) δ(q0,Ʌ)={q1,q2} \\nii) δ(q,a)=δ1(q,a) for q in Q1-{f1} & a in ∑1U{Ʌ} \\niii) δ(q,a)=δ2(q,a) for q in Q2-{f2} & a in ∑2U{Ʌ} \\niv) δ(f1,Ʌ)=δ(f2,Ʌ)={f0} \\nThus all the moves of M1 and M2 are in M. \\nThere is a path labelled x in M from q1 to f1 or a path in M2 from q2 to f2. \\nHence L(M)=L(M1) U L(M2) \\nL(M)={x|x is in L(M1) or x is in L(M2)} \\nCase 2: r=r1 . r2 \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 32}, page_content='32 \\n \\n \\nFigure 5.2 State Diagram \\n \\nLet M1 and M2 be as in case2. \\nConstruct M=(Q1UQ2, ∑1U∑2, δ, {q1}, {f1}) \\nWhere δ is defined by, \\ni) δ(q,a)=δ1(q,a) for q in Q1-{f1} & a in ∑1U{Ʌ} \\nii) δ(f1,Ʌ)={q2} \\n \\niii) δ(q,a)=δ2(q,a) for q in Q2-{f2} & a in ∑2U{Ʌ} \\nEvery path in M from q1 to f2 is a path labelled by some string x from q1to f1 followed by \\nthe edge from f1 to q2 labelled Ʌ followed by a path labelled by some string ‘y’ from q2 to \\nf2.  \\nThus L(M)=L(M1) . L(M2) \\nCase 3: \\n \\nFigure 5.3 State Diagram \\nLet M1=(Q1,∑1,δ1,q1,{f1}) & L(M1)=L(r1) \\nConstruct M= (Q1U{q0,f0}, ∑1,δ1,q0,{f0}) \\nWhere δ is defined by \\ni) δ(q0,Ʌ)=δ(f1,Ʌ) = {q1,f0} \\nii) δ(q,a)=δ1(q,a) for q in Q1-{f1} & a in ∑1U{Ʌ} \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 33}, page_content='33 \\n \\nAny path from q0 to f0 consists either of a path from q0 to f0 on Ʌ or a path from q0 to q1 \\non Ʌ, followed by some number of paths from q1 to f1, then back to q1 on Ʌ, each labelled \\nby a string in L(M1) followed by a path from q1 to f1 on a string in L(M1). \\nHence L(M)= L(M1)* \\n \\nRegular Expressions to NFA-Ʌ Kleen’s Theorem Part-I: \\nFor each kind of RE, define an NFA-Ʌ \\nInput:  A Regular Expression r over an alphabet ∑  \\nOutput: An NFA-Ʌ   accepting L(r) \\nMethod: \\nStep 1: For \\uf065     \\n            \\n  The NFA-Ʌ recognizes {\\uf065} \\nStep 2: For a in ∑  \\n \\n  The NFA-Ʌ recognizes {a} \\nStep 3: RE=a |b \\n \\nThe NFA-Ʌ recognizes {a,b} \\nStep 4: RE=ab \\n            OR      \\nThe NFA-Ʌ recognizes {ab} \\nStep 5: RE=a* \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 34}, page_content='34 \\n \\n \\nThe NFA-Ʌ recognizes {ε,a,aa,aaa,.......} \\nStep 6: RE= a+ \\n       = a.a* \\n     Follow step 4 for construction. \\nProblems: \\nConstruct NFA -Ʌ for the following regular expression using Thompson’s Construction \\nmethod. \\na. (a|b)*abb \\na \\nb  \\n \\na/b  \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 35}, page_content='35 \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 36}, page_content='36 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFigure 5.4 State Diagram of NFA-NULL \\n6.Kleene’s Theorem Part -II \\n• Any language accepted by a finite automaton is regular.  \\n \\nFigure 6.1. Finite Automata Conversion \\n6.1Conversion of DFA to Regular Expression \\n• Formula: \\n \\n• Where  \\n• i= Start state \\n• j = Final state \\n• k = No.of states \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 37}, page_content='37 \\n \\n \\n \\nProblem 1: Obtain the regular expression for the finite automata shown below: \\n \\n \\nFigure 6.1 DFA State Diagram \\nFormula for RE: \\n \\nStep 1: Rename the states: \\n \\nFigure 6.2 DFA State Diagram \\nStep 2: Find the values of i,j,k \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 38}, page_content='38 \\n \\ni=1 (start state) \\nj=2 (final state) \\nk=2 (no. of states) \\nSubstitute I,j,k in formula: \\nFind: \\n \\n \\n \\n \\n \\nIn: \\n \\n \\nWhen K=0: \\n  \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 39}, page_content='39 \\n \\n \\nSubstitute in equation 2 and 3: \\n \\n \\n \\n   \\n \\nSubstitute in equation 3:  \\n \\n \\nWhen K=0: \\n \\n \\nSubstituting in 1: \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 40}, page_content='40 \\n \\n \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 41}, page_content=' \\n                       SCHOOL OF COMPUTING \\n                  DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUNIT – II – Theory of Computation – SCSA1302 '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 42}, page_content='CONTEXT FREE LANGUAGES AND NORMAL FORMS \\nContext-free grammars -More examples -Union, concatenations, and *’s of CFLs-Derivation \\ntrees and ambiguity -Unambiguous CFG for algebraic expressions-Normal Forms – CNF – \\nGNF \\n \\n1. Context Free Grammar \\nDefinition − A context -free grammar (CFG) consisting of a finite set of grammar rules is a \\nquadruple \\n     G= (N, T, P, S)  \\n     Where, \\n– N is a set of non-terminal symbols (N is also represented as V- the set of variables). \\n– T is a set of terminals where N ∩ T = NULL. \\n– P is a set of rules, P: N → (N ∪ T)*, i.e., the left-hand side of the production rule \\nP does have any right context or left context. \\n– S is the start symbol. \\n \\nTerminals: \\n– Defines the basic symbols from which a string in a language are composed. \\n– Represented in lower case letters. \\nNon Terminals : \\n– They are special symbols that are described recursively in terms of each other and \\nterminals. Represented in upper case letters. \\nProduction rules: \\n– It Defines the way in which NTs may be built from one another and from terminal. \\nStart Symbol: \\n– It is a special NT from which all the other strings are derived. It is always present in the first \\nrule on the LHS. \\n \\nExample: \\n     Consider the set of productions \\n<exp> →<exp>+<exp> \\n<exp>→<exp>*<exp> \\n<exp>→(<exp>) \\n<exp>→id \\n \\nWe apply productions \\nrepeatedly (id+id)*id '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 43}, page_content='<exp>  ⇒ <exp>*<exp> \\n⇒ (<exp>)*<exp> \\n⇒ (<exp>+<exp>)*<exp> \\n⇒ (id+id) * id \\nWhere (id+id) is the word in the language of <exp> \\n- Use E instead of \\n<exp> Productions: \\nE→ E+E \\nE→ \\nE*E \\nE→\\n(E) \\nE→id \\nG=({E},{+,*,id,(,)},P,E) \\n \\nDefinition 2: The language generated by a CFG \\nLet G=(N,T,P,S) be a CFG. The language generated by G is \\nL(G) = {x∈ Σ∗|s⇒G∗x} \\nDefinition 3: \\nA language L is a CFL if there is a CFG ‘G’ so that L = L(G) \\n \\n1.1 Problems: \\n1. Given a CFG, find the language generated by G \\n(i) G=(N,T,P,S) where N={S}, T={a,b} \\nP={S→aSb, S→ab} \\nS=>ab    S=>aSb    S=>aSb    S=>aSb \\n           =>aaSbb                  =>aabb     =>aaSbb \\n=>aaabbb        =>aaaSbbb                                               \\n=>aaaabbbb                              \\n W= { ab, aabb,aaabbb,aaaabbbb,……..}     \\n             L(G)={anbn |n≥1} \\n \\n(ii) G=(P,{Ꜫ,0,1},P,P} \\nP: P→0 | 1 | Ꜫ |0P0 |1P1 \\nP=>0 \\nP=>1 \\nP=>Ꜫ \\nP=>0P0      P=>0P0    P=>0P0      P =>0P0 '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 44}, page_content='    =>010        =>00        =>000           =>00P00 \\n                 =>00100   \\nP =>1P1                       P =>0P0 \\n    =>10P01      =>00P00 \\n    =>10101      =>001P100 \\n        =>0010100 \\nW={ꓥ, 0,1,00,010,000, 00100, 0010100,   10101,….} \\nL(G)={language of palindromes} \\n \\n1.2 CFG Corresponding To A Language \\n1.2.3 For the given L(G), design a CFG. \\ni.Language consisting of even number of 1’s \\nT={1,Ꜫ} \\n        W={Ꜫ,11,1111,111111,….} \\nP: \\nS -> Ꜫ \\nS -> 1S1   \\n     \\nG=({S},{1,Ꜫ},P,S) \\nii. Design a CFG for a language consisting of arithmetic expression. \\nT={id,+,-,*,/,(,)} \\nW={id,id+id,id-id,id*id,id/id, id+id*id,(id-id)/id,……} \\nP: S -> id \\n     S -> S+S \\n     S -> S-S \\n    S ->S*S \\n    S ->S/S \\n(or) \\nS->id |S+S |S-S|S*S |S/S |(S) \\nG=({S},{+,-,*,/,id},P,S) \\niii. Design a CFG for a language accepting balanced  parenthesis \\nT={{,},[,],(,)} \\nW=(Ꜫ,{},[],(), {()},([]),{{}},(()),[[()]],….,{}[]{},()(),{}(),….} \\nP: S->{ S} |[S ] |(S ) |SS | Ꜫ \\n      G=({S},{ Ꜫ ,[,],{,},(,)},P,S) '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 45}, page_content=' \\niv. L={𝒂𝒏𝒃𝒎| 𝒎>𝒏  𝒂𝒏𝒅 𝒏≥𝟎} \\nT={a,b} \\nW={b,bb,bbb,…,abb,abbb,…,aabbb,aaabbbb,…} \\n \\nn=0, m=1=> b \\nn=0, m=2=>b, bb, bbb,bbbb,…. \\nn=1, m=2 =>abb,abbb,abbbb,… \\nn=2, m=3=>aabbb,aaabbbb,…. \\nP: \\nB->b |bB \\nS->aSb |B \\nG=({S,B}, {a,b} , P,S) \\n \\nv. L={w|wϵ{a,b}*, 𝒏𝒂(𝒘)=𝒏𝒃(𝒘)} \\nW={Ꜫ,ab,ba,aabb,abab,baba,abba,aaabbb,bbaa,baab,….} \\nP: S-> Ꜫ |aSb |bSa  | SS \\nG=({S}, {a,b, Ꜫ } , P,S) \\n \\nvi. L={w|wϵ{a,b}*, 𝒏𝒂(𝒘)≠𝒏𝒃(𝒘)}  \\nThe problem is split into 2 cases: \\n(i) 𝑛𝑎(𝑤)>𝑛𝑏(𝑤)} \\n(ii) 𝑛𝑎(𝑤)<𝑛𝑏(𝑤)}  \\n L1=   𝑛𝑎(𝑤)>𝑛𝑏(𝑤) \\nW={a, aba, aab ,baa,aaabb,aaa,aa,aaaab,baaa,…..} \\nP1: \\nA->a| aA |AbA |AAb |bAA \\nG1=({A},{a,b},P1,A) \\n \\n L2=    𝑛𝑏(𝑤)>𝑛𝑎(𝑤)  \\nW={b,bb,bbb, abb,bab,…….} \\nP2: \\nB->b| bB |BaB |BBa |aBB '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 46}, page_content=\"G2=({B},{a,b},P2,B} \\nL=L1ᴜ L2      𝑛𝑎(𝑤)≠𝑛𝑏(𝑤) \\nP: \\nS->A|B \\nA->a| aA |AbA |AAb |bAA \\nB->b| bB |BaB |BBa |aBB \\nG=({S,A,B},{a,b},P, S} \\n \\nvii. Construct the CFG for the language having any number of a's  followed by any number \\nof b’s over the set ∑= {a} \\nW={ Ꜫ,aaaa,bbbb,aabb,abbb,…..}  \\na*.b* \\nx=aabb \\nP: \\nS->A.B \\nA->aA|Ꜫ \\nB->bB| Ꜫ \\n \\nG=({S,A,B},{a,b, Ꜫ},P,S) \\n1.3 Regular Expression to CFG \\ni. Find the CFG equivalent to a Regular Expression \\nRE=ab. (a+bb)* \\nGenerate the production for the language L1={ab} \\nA->ab \\nGenerate the production for the language L2=a+bb \\nB->a | bb \\nGenerate the production for the language L2*=(a+bb)* \\nC->Ꜫ|BC \\nRE=ab. (a+bb)* \\nP: S->A.C \\n      C->Ꜫ|BC \\n      A->ab \"),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 47}, page_content='     B->a | bb \\nG=({S,A,B,C}, {a,b, Ꜫ},P, } \\nii. Obtain the CFG for RE=(011+1)*(01)* \\nL1=(011+1) \\nL2=>(011+1)* \\nGenerate the production for the language L1=(011+1) \\nA->011|1 \\n Generate the production for the language L2=(011+1)* \\n   B->AB|Ꜫ \\nA->011|1 \\nSimilarly derive for (01)* \\nC->DC|Ꜫ \\nD->01 \\nFinally generate the concatenation of the 2 languages by adding the production \\nS->BC \\nB->AB|Ꜫ \\nA->011|1 \\nC->DC|Ꜫ \\nD->01 \\nDefinition 4: \\nRegular Grammar \\nA Grammar G=(N,T,P,S) is regular if every production takes one of the following forms: \\nB→aC \\nB→a \\nWhere B & C are NT and ‘a’ is a T \\n \\n \\n2.Derivation Trees and Ambiguity \\n2.1 Derivation: Process of deriving a string using the grammar \\n• Types : \\n– Left Most Derivation (LMD) \\n– Right Most Derivation (RMD) \\n2.2 Derivation tree is a graphical representation for the derivation. Also called as Parse Tree. \\nProperties: '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 48}, page_content='• The root node is always a node indicating start symbols. \\n• Every vertex has a label which is in (N U T U Ʌ) \\n• The leaf node has a label from T (terminal). \\n• The interior nodes are always the non-terminal nodes.  \\n• If a vertex is labeled A & if x1,x2,x3,…xn are all children of A from left then \\nA->x1x2x3….xn be a production in P. \\nLeftmost derivation & Rightmost Derivation \\n2.3 Leftmost derivation \\nIn the derivation process, if the leftmost variable is replaced at every step then the derivation is \\nleftmost derivation. \\n \\nE->E+E  | E*E | ( E ) |id \\nString:id+id*id \\nE\\n𝒍𝒎𝒅\\n⇒    E+E               E->E+E    \\n  \\n𝒍𝒎𝒅\\n⇒    id+E              E->id       \\n  \\n𝒍𝒎𝒅\\n⇒   id+E*E           E->E*E \\n  \\n𝒍𝒎𝒅\\n⇒   id+id*E          E->id  \\n \\n𝒍𝒎𝒅\\n⇒    id+id*id         E->id  \\n \\n \\n \\n \\n \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 49}, page_content=' \\n2.4 Rightmost Derivation \\nIn the derivation process, if the rightmost variable is replaced at every step then the derivation is \\nrightmost derivation. \\nE->E+E  | E*E | ( E ) |id \\nString:id+id*id \\nE  \\n𝒓𝒎𝒅\\n⇒    E+E               E->E+E   \\n    \\n𝒓𝒎𝒅\\n⇒   E+E*E            E->E*E \\n    \\n𝒓𝒎𝒅\\n⇒     E+E*id         E->id \\n    \\n𝒓𝒎𝒅\\n⇒   E+id*id          E->id \\n   \\n𝒓𝒎𝒅\\n⇒     id+id*id        E=>id \\n \\n \\n \\nDefinition: Yield of a tree: \\nIs the string of symbols obtained by only reading the leaves of the tree from left to right without  \\nconsidering the \\n  symbols called sentinal function. \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 50}, page_content=' \\nYield of the tree=id+id*id \\n \\n2.5 Problems: \\n1. For the Grammar G defined by \\nS->AB \\nB->a|Sb \\nA->Aa|bB \\nGive the derivation trees for the following sentential forms \\n(i) baSb \\nS=>AB   | S->AB \\n=>bBB    | A->bB \\n=>baB     | B->a \\n=>baSb    | B->Sb \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 51}, page_content=' \\n (ii) bAaBbB \\n \\nS=>AB                 S->AB \\n=>bBB                A->bB \\n=>bSbB             B->Sb \\n=>bABbB          S->AB \\n=>bAaBbB        A->Aa \\n \\n3. Ambiguity \\nDefinition: An Ambiguous CFG \\nA CFG G is ambiguous if there is atleat one string in L(G) having two or more distinct derivation \\ntrees(or equivalently two or more distinct LMD). \\n \\n \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 52}, page_content='12  \\ni.Is the following grammar  ambiguous: \\nE->E+E  | E*E | ( E ) |id \\n \\nConsider the String: id+id*id \\n  E  \\n𝑙𝑚𝑑\\n⇒    E+E           | E->E+E                               \\n      \\n𝑙𝑚𝑑\\n⇒    id+E           |E->id                             \\n     \\n𝑙𝑚𝑑\\n⇒     id+E*E      |E->E*E        \\n     \\n𝑙𝑚𝑑\\n⇒     id+id*E      |E->id                                        \\n     \\n𝑙𝑚𝑑\\n⇒     id+id*id     |E->id \\n \\n \\n \\n \\n \\n    \\n \\n \\n \\n \\nE   \\n𝑙𝑚𝑑\\n⇒     E*E              E-> E*E                               \\n     \\n𝑙𝑚𝑑\\n⇒     E+E*E          E->E+E                         \\n     \\n𝑙𝑚𝑑\\n⇒     id+E*E         E->id                         \\n     \\n𝑙𝑚𝑑\\n⇒     id+id*E        E->id                      \\n    \\n𝑙𝑚𝑑\\n⇒      id+id*id       E->id \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 53}, page_content='13  \\n \\n \\nThere are 2 parse trees or 2 leftmost derivations for the string ‘id+id*id’. So the given grammar is \\nambiguous. \\nii.Is the following grammar  ambiguous: \\nS->iCtS |iCtSeS |a \\nC->b \\nConsider the String: ibtibtaea \\nS \\n𝒍𝒎𝒅\\n⇒   iCtS                            S->iCtS \\n   \\n𝒍𝒎𝒅\\n⇒     ibtS                           C->b  \\n  \\n𝒍𝒎𝒅\\n⇒     ibt iCtSeS                  S-> iCtSeS \\n  \\n𝒍𝒎𝒅\\n⇒     ibtibtSeS                   C->b \\n  \\n𝒍𝒎𝒅\\n⇒     ibtibtaeS                   S->a \\n          \\n𝒍𝒎𝒅\\n⇒     ibtibtaea                   S->a \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 54}, page_content='14  \\n \\n \\n \\n \\n \\nS\\n𝒍𝒎𝒅\\n⇒   iCtSeS \\n𝒍𝒎𝒅\\n⇒  ibtSeS \\n𝒍𝒎𝒅\\n⇒  ibtiCtSeS \\n𝒍𝒎𝒅\\n⇒  ibtibtSeS \\n𝒍𝒎𝒅\\n⇒  ibtibtaeS \\n𝒍𝒎𝒅\\n⇒  ibtibtaea \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 55}, page_content='15  \\n \\n \\nThere are 2 parse trees or 2 leftmost derivations for the string ‘ibtibtaea’. So the given \\ngrammar is ambiguous. \\niii. Is the following grammar  ambiguous: \\nS->AB | aaB \\nA->a | Aa \\nB->b \\nString: aab \\nS \\n𝒍𝒎𝒅\\n⇒      AB        S->AB       \\n  \\n𝒍𝒎𝒅\\n⇒     AaB        A->Aa \\n  \\n𝒍𝒎𝒅\\n⇒     aaB         A->a \\n  \\n𝒍𝒎𝒅\\n⇒     aab         B->b \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nS\\n𝒍𝒎𝒅\\n⇒   aaB            S->aaB \\n  \\n𝒍𝒎𝒅\\n⇒   aab              B->b \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 56}, page_content='16  \\n \\nThere are 2 parse trees or 2 leftmost derivations for the string ‘aab’. So the given grammar is \\nambiguous. \\nAn unambiguous CFG for Algebraic expression \\nIf a CFG is ambiguous , it is often possible and usually desirable to find an equivalent unambiguous \\nCFG. \\n4. Normal Forms: \\nChomsky Normal Form(CNF) \\nGreibach Normal Form(GNF) \\n4.1Chomsky Normal Form(CNF): \\nA CFG is in CNF if every production is one of two types \\nA->BC \\nA->a \\nWhere A,B and C are Non terminals and ‘a’ is a terminal \\n4.1.1.Converting a CFG to CNF \\ni.Let G be the CFG with productions \\nS->AACD \\nA->aAb | ꓥ \\nC->aC |a \\nD ->aDa | bDb |ꓥ \\nStep 1: \\nEliminating ꓥ productions \\nAny production A for which P contains the production A->ꓥ is nullable \\nNullable variable: A->ꓥ   D->ꓥ \\nS->AACD | ACD  |CD | AAC |AC |C \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 57}, page_content='17  \\n     A->aAb | ab \\nC->aC |a \\nD ->aDa | bDb |aa |bb \\nStep 2: \\nEliminating unit productions S->C \\nS->AACD | ACD  |CD | AAC |AC | aC |a \\nA->aAb | ab \\nC->aC |a \\nD ->aDa | bDb |aa |bb \\nStep 3:Restricting the right sides of the productions to single terminals or strings of two or \\nmore variables(NON TERMINALS). \\nS->AACD | ACD  |CD | AAC |AC | Xa C |a \\nA-> Xa A Xb | Xa Xb \\nC-> Xa C |a \\nD -> XaD Xa | Xb D Xb | Xa Xa  | Xb Xb \\nXa->a \\nXb->b \\nStep 4: \\nS->AT1 |AT2 |CD |AT3 |AC | Xa C |a \\nT1->AT2 \\nT2->CD \\nT3->AC \\nA-> XaT4  |  Xa Xb \\nT4-> A Xb \\nC-> Xa C |a \\nD->XaT5 | XbT6| Xa Xa  | Xb Xb \\nT5->D Xa \\nT6-> D Xb \\nXa->a '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 58}, page_content='18  \\nXb->b \\n4.3 Greibach Normal Form (GNF) \\nLet G=(N, T, P, S) be a CFG. The CFG ‘G’ is said to be in GNF, if all the production are of the \\nform: \\nA->aα \\nWhere a ↋ T and α ↋ N* \\n A non-terminal generating a terminal which is followed by any number of non-terminals.  \\nFor example, A → a. \\n                         S → aASB. \\nStep 1: Convert the grammar into CNF. \\nStep 2: Rename the non-terminals to A1, A2, A3,… \\nStep 3: In the grammar, convert the given production rule into GNF form.  \\nProblem 1: \\nS-> AB1 |0S | ε \\nA->00A | B \\nB-> 1A1 \\nStep 1: Eliminate null productions. \\nS-> ε \\nS->AB1 | 0S | 0 \\nA->00A |B \\nB->1A1 \\nStep 2: Eliminate unit productions \\nA->B  is the unit production. \\nS->AB1 |0S |0 \\nA->00A |1A1 \\nB->1A1 \\nStep 3: Restricting right hand side production with single terminal symbol or two or more \\nnon terminals. \\nX->0 '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 59}, page_content='19  \\nY->1 \\nS->ABY | XS |0 \\nA->XXA |YAY \\nB->YAY  \\nStep 4: Final CNF \\nX->0     Y->1 \\nS->AT1      T1->BY \\nS->XS | 0 \\nA->XT2    T2->XA       A->YT3      T3->AY \\nB->YT3 \\nStep 5: Rename Non terminal as A1, A2, A3,…….. \\nS=A1, A= A2, B=A3, X=A4, Y=A5, T1=A6, T2=A7, T3=A8 \\nX->0     Y->1 \\nS->AT1      T1->BY \\nS->XS | 0 \\nA->XT2    T2->XA       A->YT3      T3->AY \\nB->YT3 \\n \\nA4->0       A5->1 \\nA1->A2A6 | A4A1 | 0 \\nA2->A4A7 | A5A8 \\nA3->A5A8 \\nA6->A3A5 \\nA7->A4A2 \\nA8->A2A5 \\n Step 6: Obtain productions to the form A->aα \\nFinal CFG is \\nA4->0     A5->1 \\nA2->0A7 |1A8 \\nA3->1A8 \\nA7->0A2 \\nA8->0A7A5 | 1A8A5 \\nA6->1A8A5 \\nA1->0A7A6 | 1A8A6 | 0A1 |0 '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 60}, page_content='1 \\n \\n \\n \\nSCHOOL OF COMPUTING \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUNIT – III – THEORY OF COMPUTATION – \\nSCSA1302 '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 61}, page_content='2 \\n \\n \\n \\n \\nPUSH DOWN AUTOMATA (PDA) \\nPushdown automata - Introduction - Definition - Deterministic pushdown automata - PDA \\ncorresponding to a given context-free grammar – Context-free Grammar corresponding to PDA \\n- Pumping Lemma for CFG \\n1. Push Down Automata \\n1.1. Drawback of Finite Automata \\n\\uf0b7 can remember only a finite amount of information \\n\\uf0b7 No memory is used in FA \\n2. Introduction \\n• PDA can remember an infinite amount of information. \\n• Memory used – Stack \\n• A PDA is more powerful than FA. \\n• Any language which can be acceptable by FA can also be acceptable by PDA. \\n• PDA also accepts a class of languages which cannot be accepted by FA. \\n• PDA recognizes CFL. \\nFA + stack = PDA \\n3. Definition \\nThe PDA can be defined as a collection of 7 tuples: \\nM=( Q, ∑, Γ, q0, Z0, F, δ ) \\nQ: the finite set of states \\n∑: the input set \\nΓ: a stack symbol which can be pushed and popped from the stack q0: \\nthe initial state \\nZ0: a start symbol which is in Γ. \\nF: a set of final states. \\nδ: Transition function which is used for moving from current state to next state. \\nδ: Q x {Σ ∪ ε} x Γ -> Q x Γ* \\n(i.e) δ(q,a,x)=(p,α) '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 62}, page_content='3 \\n \\nfrom state ‘q’ for an input symbol ‘a’, and stack symbol ‘x’, goto state ‘p’ and x is replaced by \\nstring ‘α’. \\n3.1. Instantaneous Description (ID) \\n• An instantaneous description is a triple ID \\n(q, w, α) \\nWhere:  \\n\\uf0b7 Q describes the current state. \\n\\uf0b7 w describes the remaining input. \\n\\uf0b7 α describes the stack contents, top at the left. \\nExample Derivation: (p, b, T) ⊢ (q, w, α) \\n3.2. Definition: Acceptance by a PDA \\n1. Acceptance by Final State: \\nIf M =(Q, ∑, Γ, δ, q0, Z, F) is a PDA and the language L(M) accepted by the final state is \\ngiven by: x∈∑* and x is accepted by M if, \\nL(M) = {x | (q0, x, Z0) ⊢* (q,Ʌ ,α)} \\nWhere q∈Aα∈Γ* \\n \\n2. Acceptance by Empty Stack: \\nFor each PDA, M=(Q, ∑, Γ, δ, q0, Z, F) the language accepted by empty stack is given by \\nL(M) = {x | (q0, x, Z0) ⊢* (q,Ʌ , Ʌ)} \\nFor any state q∈A and x∈∑* \\n \\nLanguage Acceptance: \\nA language L ⊆∑* is said to be accepted by M, if L is precisely the set of string accepted by \\nM. \\nL=L(M) \\n4. Construction of PDA \\n1. Design a PDA for accepting a language {anbn | n>=1}. \\nSolution: \\n1. Decide the nature of the language b’s followed by ‘a’. \\n2. Execution procedure using stack: \\n\\uf0b7 Push all a’s on to stack. \\n\\uf0b7 For every ‘b’ pop out an ‘a’. \\n3. Define the states \\n\\uf0b7 q0 – push all a’s on to the stack. \\n\\uf0b7 q1 – when a ‘b’ encounters, pop ‘a’ from stack. \\n\\uf0b7 q2 – accepting state. \\nPDA Diagram '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 63}, page_content='4 \\n \\n \\n \\n \\n \\n \\nTransition Table: \\n \\nMove No. State Input \\nSymbol \\nTop of stack Moves \\n1 q0 a Z0 (q0,az0) \\n2 q0 a a (q0,aa) \\n3 q0 b a (q1,Ʌ) \\n4 q1 b a (q1,Ʌ) \\n5 q1 Ʌ Z0 (q2,z0) \\nAll other combinations None \\n \\nTrace the moves: a3b3 => aaabbb \\nMove No. Resulting state Input Stack \\n- q0 aaabbb Z0 \\n1 q0 aabbb az0 \\n2 q0 abbb aaz0 \\n2 q0 bbb aaaz0 \\n3 q1 bb aaz0 \\n4 q1 b az0 \\n4 q1 Ʌ Z0 \\n5 q2 Ʌ Z0 \\nAccepted \\n \\nTrace the moves: a2b=> aab \\nMove No. Resulting state Input Stack \\n- q0 aab Z0 \\n1 q0 ab az0 \\n2 q0 b aaz0 \\n3 q1 Ʌ az0 \\nRejected \\n \\nInstantaneous Description (ID) \\n(q0, aabb,z0) |- (q0, abb, az0) \\n|- (q0, bb, aaz0) \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 64}, page_content='5 \\n \\n|-(q1, b, az0) \\n|-(q1,Ʌ, z0) \\n|-(q2, Ʌ, z0) \\nString Accepted \\n \\n \\n2. Construct PDA for the language L={xCxr | x ↋ {a,b}*} \\nSolution \\n1. Nature of the language: \\nA string ‘x’ followed by constant ‘C’ followed by reversed string. \\n2. Execution procedure: \\n\\uf0b7 Push the string ‘x’ into the stack until ‘C’ is encountered. \\n\\uf0b7 When ‘C’ is encountered, don’t do any operation. \\n\\uf0b7 After that, pop out each element from the stack for the string xr. \\n3. Define the states: \\n\\uf0b7 q0 - Push all input symbols until ‘C’. \\n\\uf0b7 q1 – when ‘C’ is encountered, Pop. \\n\\uf0b7 q2 – accepting state. \\nPDA \\n \\n \\n \\n \\nTransition Table \\n \\nMove No. State Input Symbol Top of stack Moves \\n1 q0 a Z0 (q0,az0) \\n2 q0 b Z0 (q0,bz0) \\n3 q0 a a (q0,aa) \\n4 q0 a b (q0,ab) \\n5 q0 b b (q0,bb) \\n6 q0 b a (q0,ba) \\n7 q0 C a (q1,a) \\n8 q0 C b (q1,b) \\n9 q0 C Z0 (q1,z0) \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 65}, page_content='6 \\n \\n10 q1 a a (q1,Ʌ) \\n11 q1 b b (q1, Ʌ) \\n12 q1 Ʌ Z0 (q2,z0) \\nAll other combinations  - No moves \\n \\nTrace the moves: abCba \\n \\nMove No. Resulting state Input Stack \\n- q0 abCba Z0 \\n1 q0 bCba az0 \\n6 q0 Cba baz0 \\n8 q1 ba baz0 \\n11 q1 a az0 \\n10 q1 Ʌ Z0 \\n12 q2 Ʌ Z0 \\nAccept \\n \\nTrace the moves: abCa \\n \\nMove No. Resulting state Input Stack \\n- q0 abCa Z0 \\n1 q0 bCa az0 \\n6 q0 Ca baz0 \\n8 q1 a baz0 \\n    \\nRejected \\n \\n3. Consider the CFG \\nS->[S] | {S} | Ʌ \\nGenerate the CFL and PDA. \\nSolution \\n1. Nature of the language \\nCFL = {Ʌ, [], {}, [{}], {[]}, [{{}}],….} \\nOpen parenthesis followed by symbols and then closed parenthesis. \\n2. Define the states: \\nq0 – When all the open parenthesis are encountered. \\nq1 – when all the closed parenthesis are encountered \\nq2 – accepting state. '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 66}, page_content='7 \\n \\n \\n \\n \\n \\nTransition Table: \\n \\nMove No. State Input Symbol Top of stack Moves \\n1 q0 [ Z0 (q0,[z0) \\n2 q0 { Z0 (q0,{z0) \\n3 q0 [ [ (q0,[[) \\n4 q0 [ { (q0,[{) \\n5 q0 { { (q0,{{) \\n6 q0 { [ (q0,{[) \\n7 q0 } { (q1, Ʌ) \\n8 q0 ] [ (q1, Ʌ) \\n9 q1 } { (q1, Ʌ) \\n10 q1 ] [ (q1, Ʌ) \\n11 q1 Ʌ Z0 (q2,z0) \\n12 q0 Ʌ Z0 (q2,z0) \\nAll other combinations No moves \\n \\n \\n \\n \\n \\n \\nTrace the moves: {[{}]} \\n \\nMove No. Resulting state Input Stack \\n- q0 {[{}]} Z0 \\n2 q0 [{}]} {z0 \\n4 q0 {}]} [{z0 \\n6 q0 }]} {[{z0 \\n7 q1 ]} [{z0 \\n10 q1 } {z0 \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 67}, page_content='8 \\n \\n9 q1 Ʌ Z0 \\n11 q2 Ʌ Z0 \\nAccept \\n \\nTrace the moves: {[{] \\n \\nMove No. Resulting state Input Stack \\n- q0 {[{] Z0 \\n2 q0 [{] {z0 \\n4 q0 {] [{z0 \\n6 q0 ] {[{z0 \\n No Move   \\nRejected \\n \\n4. \\n5. Parsing: \\n\\uf0b7 To derive a string using the production rules for a grammar. \\n\\uf0b7 It is used to check whether or not a string is syntactically correct. \\n\\uf0b7 Parser takes the inputs and builds a parse tree. \\n5.1. Types of parser \\nTop down Parser- Parsing starts from the top with the start symbol and derives a string  using \\na parse tree. \\nBottom up parser- Starts from the bottom with the string and comes to the start symbol using \\na parse tree. \\n5.2. Design of Top down parser \\n1. Push the start symbol onto the stack. \\n2. If the top of the stack contains a NT, pop it out of the stack and push its right hand \\nside of the production. \\n3. If the top of the stack matches with input symbol being read, pop it. \\n4. If the input string is fully read and the stack is empty go to final state. \\n \\n5.3. PDA Corresponding to CFG \\n \\nIn 2 ways, PDA can simulate a derivation in the grammar. \\n\\uf0b7 Top Down Parsing - LMD \\n\\uf0b7 Bottom Up Parsing– RMD \\n \\n5.3.1. Top Down Parsing: PDA corresponding to CFG: \\n \\nLeft Most Derivation is used \\nStatement: '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 68}, page_content='9 \\n \\nLet G=(N,T,P,S) be a Context Free G, then there is a push down automata M, so that \\nL(M)=L(G) \\nDefine ‘M’ as: \\nM=(Q,∑ , Γ, δ, q0, Z0, F) \\n \\nWhere, Q={q0,q1,q2} \\nΓ = N U ∑ U {z0} \\nA = {q2} \\n \\na) δ(q0,Ʌ,z0)={(q1,Sz0)} \\n \\nb) for every A∈N, δ (q1,Ʌ,A)={(q1, α) | A->α is a production in G} \\n \\nc) for every a∈∑, δ (q1,a, a)={(q, Ʌ)} \\n \\nd) δ (q1,Ʌ,z0)={(q2,z0)} \\n \\n \\n \\n \\n \\n \\nQ={q0,q1,q2} \\nA={q2} \\n \\n5.3.2. Construction of PDA \\n \\n1. Construct PDA for the language \\nL={x∈{a,b}*|na(x)>nb(x)}}  \\nS->a | aS | bSS | SSb| SbS \\nSolution: \\nLet M=(Q, ∑, Γ, δ, q0, Z, F) \\n \\nQ={q0,q1,q2} \\n∑={a,b} \\nΓ={S,a,b,z0} \\nF={q2} \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 69}, page_content='10 \\n \\n \\n \\n \\n \\nTransition Table: \\nState Input Stack \\nSymbol \\nMoves \\nq0 Ʌ Z0 (q1,Sz0) \\nQ1 Ʌ S (q1,a),(q1,aS),(q1,bSS),(q1,SSb),(q1,SbS) \\nQ1 a a (q1, Ʌ) \\nQ1 b b (q1, Ʌ) \\nQ1 Ʌ Z0 (q2,z0) \\nAll other combination none \\n \\nS->a | aS | bSS | SSb| SbS \\n \\nExample: abbaaa \\nS->a | aS | bSS | SSb| SbS \\n \\nS=>SbS \\n=>abS \\n=>abbSS \\n=>abbaS \\n=>abbaaS \\n=>abbaaa \\nS->SbS \\nS->a \\nS->bSS \\nS->a \\nS->aS \\nS->a \\n \\n \\nSequence of moves: parsing \\n(q0, Ʌ abbaaa,z0) -| ( q1, Ʌ abbaaa ,SZ0) \\n \\n-| ( q1, Ʌ abbaaa, SbSZ0) \\n(q1, abbaaa, abSZ0) \\n(q1, bbaaa, bSz0) \\n(q1, baaa, Sz0) \\n( q1, baaa, bSSz0) \\n(q1, aaa, SSz0) \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 70}, page_content='11 \\n \\n(q1, aaa, aSz0) \\n(q1,aa, Sz0) \\n(q1,aa, aSz0) \\n(q1.a, Sz0) \\n(q1,a , az0) \\n(q1, Ʌ, z0) \\n(q2) \\n \\n \\n2. Construct PDA \\nS->S+X | X \\nX->X*Y | Y \\nY->(S) | id \\nString: id+id*id \\nSolution: \\nLet M=(Q, ∑, Γ, δ, q0, Z0, F) \\nQ={q0,q1,q2} \\n∑={ +,*,id,(,)} \\nΓ={ z0,S,X,Y, +,*,id,(,)} \\nA={q2} \\n \\nFigure 3.6 State Diagram \\n \\n \\nString: id*id+id \\n \\nS=>S+X S->S+X \\n=>X+X S->X \\n=>X*X+X X->X*X \\n=>Y*X+X X->Y \\n-> id*X+X Y->id \\n=>id*Y+X X-> Y \\n=>id*id+X Y->id \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 71}, page_content='12 \\n \\n=>id*id+Y X->Y \\n=>id*id+id Y->id \\n(q0,id*id+id,z0) -| (q0,id*id+id,Sz0) \\n(q1,id*id+id, S+X) \\n(q1, id*id+id, X+X) \\n(q1, id*id+id, X*X+X) \\n(q1, id*id+id, Y*X+X) \\n(q1, id*id+id, id*X+X) \\n(q1, *id+id, *X+X) (q1, \\nid+id, X+X) (q 1,id+id, \\nY+X) \\n(q1, id+id, id+X) \\n(q1, +id, +X) \\n(q1, id, X) \\n(q1, id, Y) \\n(q1, id, id) \\n \\n5.3.4. Bottom-Up PDA \\n• Right Most Derivation in reverse is used. \\nSteps: \\n– Push the current input symbol onto the stack. \\n– Replace the right-hand side of a production at the top of the stack with its left- \\nhand side. \\n– If the top of the stack element matches with the current input symbol, pop it. \\n– If the input string is fully read and only if the start symbol ‘S’ remains in the \\nstack, pop it and go to the final state ‘F’. \\nProblem 1:  \\nP: S->S+T \\nS->T \\nT->T*a \\nT->a \\nString: a+a*a \\nRight Most Derivation: \\nS=>S+T [S->S+T] \\n=>S+T*a [T->T*a] \\n=>S+a*a [T->a] \\n=>T+a*a [S->T] \\n=>a+a*a [T->a] \\n \\nMove Production Stack Unread Input \\n- - Z0 a+a*a \\nshift - aZ0 +a*a \\nReduce T->a TZ0 +a*a \\nReduce S->T SZ0 +a*a \\nShift - +SZ0 a*a \\nShift - a+SZ0 *a '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 72}, page_content='13 \\n \\nReduce T->a T+SZ0 *a \\nShift - *T+SZ0 A \\nShift - a*T+SZ0 - \\nReduce T->T*a T+SZ0 - \\nReduce S->S+T S Z0 - \\nAccept \\n \\n \\n6. Deterministic Push down automata \\n \\nLet M=(Q,∑ , Γ, δ, q0, Z, F) be a PDA, M is deterministic if there is no configuration for \\nwhich M has a choice of more than one move. \\nIf M is deterministic it satisfies the following condition: \\n \\ni) For every q ∈ Q, a ∈ ∑ U { Ʌ } and x ∈ Γ then the set \\nδ(q, a, x) has at most one element \\n \\nii) For any q ∈ Q, x ∈ Γ, if δ(q, Ʌ, x) ≠ φ then \\nδ(q, a, x) = φ for every a ∈ ∑. \\n \\nProblem : \\nConstruct DPDA for the language \\n \\nL={x∈{a,b}*|na(x)>nb(x)} \\nsolution \\nDPDA with Null transition : \\n \\nW= {a, aa, aaa, aab, aba,....., baa, bbaaa, aabba, aaab,...} \\n \\n \\n \\n \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 73}, page_content='14 \\n \\nW= {a, aa, aaa, aab, aba,....., baa, bbaaa, aabba, aaab,...} \\n \\n \\n \\nMove No. State Input Symbol Top of stack Moves \\n1 q0 a Z0 (q1,az0) \\n2 q0 a a (q1,aa) \\n3 q0 Ʌ a (q1,a) \\n4 q0 b Z0 (q0,bz0) \\n5 q0 b b (q0,bb) \\n6 q0 a b (q0, Ʌ) \\n7 q0 b a (q0, Ʌ) \\n8 q1 a a (q1,aa) \\n9 q1 b a (q0, Ʌ) \\nAll other combinations None \\n \\nDPDA without Ʌ \\nW= {a, aa, aaa, aab, aba,....., baa, bbaaa, aabba, aaab,...} \\n \\n \\n \\n \\n \\n \\n \\n \\nTransition Table: \\n \\nMove No. State Input Symbol Top of stack Moves \\n1 q0 b Z0 (q0,b Z0) \\n2 q0 a b (q0,Ʌ) \\n3 q0 b b (q0,bb) \\n4 q0 a Z0 (q1, Z0) \\n5 q1 b a (q1, Ʌ) \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 74}, page_content='15 \\n \\n6 q1 a Z0 (q1,aZ0) \\n7 q1 a a (q1,aa) \\n8 q1 b Z0 (q0, Z0) \\nAll other combinations None \\n \\nTrace the moves: aaaba \\n \\nMove No. Resulting state Input Stack \\n- q0 aaaba Z0 \\n4 Q1 aaba Z0 \\n6 Q1 aba Az0 \\n7 Q1 ba Aaz0 \\n5 Q1 a Az0 \\n7 Q1 - Aaz0 \\nAccept \\n \\n7. Pumping Lemma \\nCFL- We can always find two pieces of any sufficiently long string to pump in tandem .i.e. if \\nwe repeat each of the two pieces the same number of times, we get another string of the \\nlanguage. \\n\\uf0b7 Pumping Lemma is used to prove that a language is not CFL. \\n\\uf0b7 It should never be used to show a language is regular. \\n \\nFor any language L, we break its strings into five parts and pump second and fourth substring. \\n \\nLet ‘L’ be any CFL. Then there is a constant ‘n’ depending on L, such that if ‘Z’ is in L and \\n|z|>=n, then we may write, \\nZ=uvwxy \\nuviwxiy ↋ L, For all i>0, \\n|vx|>=1 \\n|vwx|<=n \\n7.1. Procedure \\n\\uf0b7 Assume that L is context free. '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 75}, page_content='16 \\n \\n\\uf0b7 It has to have a pumping length(say n) \\n\\uf0b7 Find a string ‘z’ in L such that |z]>=n. \\n\\uf0b7 Divide z into uvwxy. \\n\\uf0b7 Show that uviwxiy ∉ L \\n \\n \\nProblem 1 \\nL={anbncn, n>=0} is not a CFL. \\nSolution: \\ni. Assume ‘L’ is a CFL. \\ni. Let ‘n’ be a natural number obtained by using pumping lemma. \\nii . Let z= anbncn |z|=n+n+n=3n \\ni v .  Split z into uvwxy such that |vx|>=1, |vwx|<=n \\nAssume z=an-iaibn-j-kbjbkcn \\nu=an-i v=ai    w=bn-j-k x=bj y=bkcn \\nfor i=2 \\n=> uv2wx2y =>an-iaiaibn-j-kbjbjbkcn \\n=>an+ibn+jcn ∉ L \\n \\nEg) n=4 \\nZ=a4b4c4=>aaaabbbbcccc \\nu=a v=aa  w=abbbbc x=c y=cc \\nLet i=2 \\nuviwxiy =>uv2wx2y=>aaaaaabbbbccccc=>a6b4c5∉L \\nTherefore the given language is not CFL. \\n \\nProblem 2: \\nL={0p|p is prime is not CFL. \\nSolution: \\ni. Assume ‘L’ is a CFL. \\ni i . Let ‘n’ be a natural number obtained by using pumping lemma. \\ni i i . Let P be a prime no. such that p>=n \\nZ=0pϵ L |z|=p>=n \\ni v . Split z into uvwxy such that |vx|>=1, |vwx|<=n \\nLet v=0k x=0l such that k+l>=1 and <=n \\nHence |uwy|=p-k-l \\nIf we pump v and x p+1 times \\n|uvwxy|=|uwy|+|v(p+1).x(p+1)| \\n=p-k-l+k(p+1)+l(p+1) \\n=p-k-l+pk+k+pl+l \\n=p+pk+pl \\n=p(k+l+1) \\nWhich is not prime. \\n '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 76}, page_content='1 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSCHOOL OF COMPUTING \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\n \\n \\nUNIT – IV – THEORY OF COMPUTATION – \\nSCSA1302 '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 77}, page_content='2 \\n \\n \\n \\nTURING MACHINE \\nTuring machines - Models of computation and the Turing thesis - Definition of TM and TM as \\nlanguage acceptor - Non-deterministic TM and Deterministic TM – Universal TM \\n1. Introduction \\n \\n1.1. Need for Turing Machine \\nDescribe an abstract machine™ that is widely accepted as a general model of computation \\n \\nModel of Computation \\nEX: an bn cn- this kind of computation PDA needs 2 or 3 stacks \\nBut Turing machine can handle this type of computation using queue (Tape) \\n \\nEx: L = {SS | S ∈ {a,b}* } \\n-Compare the first half of the string to the 2nd half then queue is more appropriate than stack. \\n- TM is powerful than PDA \\n \\n- Recognizes all types of languages like RL, CFL, CSL \\n \\n1.2. Church Turing thesis \\n \\n-By Alonzo church \\n \\n“Any algorithmic procedure that can be carried out by a human, a team of humans or a \\ncomputer- can be carried out by some Turing machine” \\n1.3. Turing machine proposal \\n \\n \\n \\n \\nFigure 4.1 Tape \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 78}, page_content='3 \\n \\n\\uf0b7 Tape head is centered on one of the squares of the tape. \\n\\uf0b7 Tape head reads the symbol in the current square(Fig 4.1) \\n\\uf0b7 Moving the tape head one square to the \\nLeft | Right | Stationary => I | R | S \\n2. Definition of TM \\n \\nA TM can be formally described as a 7-tuple abstract machine \\n(Q, Γ, ∑, δ, q0, B, F) \\nwhere – \\n \\nQ- Finite set of states \\n \\nΓ – Finite set of allowable tape symbol \\n \\n∑ - Set of input symbol \\n \\nB – Symbol of Γ - blank symbol(∆) \\nq0 – Start state \\nF – Final state \\n \\nδ : Q X Γ \\uf0e0 Q X Γ X {L, R, S} \\nEX: δ ( q1, x) = (q2, y, D) \\n \\n \\nFigure 4.2 Sample Transition \\n \\n\\uf0b7 From state q1 with x, replace X |Y , go to state q1, and move the tape head either D = { \\nL,R, S}(Fig 4.2) \\nTuring machine can \\n \\n(i) Crash: If in this situation D=L but the tape head is scanning square 0, the leftmost \\nsquare, the tape head is not allowed to move. \\n(ii) Halt: r=h, the move causes the turing machine to halt. \\nq1 \\n X |Y,D \\n q2 '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 79}, page_content='4 \\n \\nTuring Machine can be represented by \\n \\n1. Transition Table \\n \\n2. Instantaneous Description \\n \\n3. Transition Diagram \\n \\n2.1. Instantaneous Description (ID) \\n \\nInstantaneous Description of a turing machine is given by α1qα2 \\n \\nwhere, q- is the current state of M, qϵQ \\n \\nα1, α2 ϵ Γ* - the contents of the tape upto the rightmost non blank symbol. \\n \\nInitial ID: q0 α1α2 \\nFinal ID: α1α2qB \\nTuring Machine can do one of the following things: \\n \\n(i) Halt and accept by entering into the final state. \\n \\n(ii) Halt and reject (δ is not defined) \\n \\n(iii) Turing machine will never halt and enters into an infinite loop. \\n \\nDefinition: Language acceptance by Turing Machine \\n \\nLet M=(Q, Γ, ∑, δ, q0, B, F) be a turing machine. The language L(M) accepted by M is \\ndefined as : \\nL(M)={ w | q0w Ⱶ* α1α2p } \\nWhere, wϵ∑*, PϵF, α1α2 ϵ Γ* \\nThe language accepted by the turing machine is REL( Recursively Enumerable Language) \\n \\n2.2. construction of Turing Machines \\n \\n1. Obtain TM to accept the language \\nL = { 0n 1n |n >= 1} \\nSolution: \\n \\nW = {01,0011,000111,……} '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 80}, page_content='5 \\n \\n∆ 0 0 1 1 ∆ ∆ ∆ ∆ ∆ ∆ \\n \\n \\nExecution Procedure: \\n \\n∆0 0 1 1 ∆ \\n \\n∆ 0 0 1 1 ∆ \\n \\n∆ X 0 1 1 ∆ \\n \\nB X 0 1 1 B \\n \\nB X 0 Y 1 B \\n \\nB X 0 Y 1 B \\n \\nB X 0 Y 1 B \\nB X X Y 1 B \\nB X X Y 1 B \\nB X X Y Y B \\nB X X Y Y B \\nB X X Y Y B \\nB X X Y Y B \\nB X X Y Y B '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 81}, page_content='6 \\n \\n \\n \\n \\n \\n \\nDefine Tuples \\n \\nqs-start state \\nQ={qs,qo,q1,q2,q3,h} \\nF={h} \\n∑={0,1} \\nΓ={0,1,X,Y,B} \\nδ : Transition table : \\n \\nstate 0 1 X Y B \\nQs - - -  (q0,B,R) \\nq0 (q1,X,R)   (q3,y,R)  \\nq1 (q1,0,R) (q2,Y,L)  (q1,Y,R)  \\nq2 (q2,0,L)  (q0,X,R) (q2,Y,L)  \\nq3    (q3,y,R) (h,B,S) \\n \\n \\nSequence of Moves: 0011 (ID) \\n \\n(q0, B 0 0 1 1 B) |- (q1, B 0 0 1 1B) \\n \\n|- (q2, B X 0 1 1 B) \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 82}, page_content='7 \\n \\n|- ( q2, B X 0 1 1 B) \\n \\n|- (q3, B X 0 Y 1 B) \\n \\n|- (q3, B X 0 Y 1 B ) \\n \\n|- ( q1, B X 0 Y 1 B) \\n \\n|- ( q2, B X X Y 1 B) \\n \\n|- (q2, B X X Y 1 B) \\n \\n|- (q3, B X X Y Y B) \\n \\n|- (q3, B X X Y Y B ) \\n \\n|- ( q1,B X X Y Y B) \\n \\n|- (q4, B X X Y Y B) \\n \\n|- ( q4, B X x Y Y B ) \\n \\n|- ( q5, B X X Y Y B ) \\n \\n \\n \\n2. Construct a Turing Machine to accept palindrome over {a,b} \\n \\n\\uf0b7 Even palindrome - abba \\n\\uf0b7 Odd palindrome- aba \\n\\uf0b7 Not a palindrome -abb \\nEven Palindrome: abba \\n \\nΔ a b b a Δ Δ Δ …….. \\nOdd Palindrome: aba \\n \\n∆ a b a ∆ ∆ ∆ ∆ ∆ ……….. \\nNot a Plalindrome: abb \\n \\nΔ a b b Δ Δ Δ  …… '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 83}, page_content='8 \\n \\n \\n \\n \\nDefine Tuples \\n \\nqs-start state \\nQ={qs,q0,q1,q2,q3,q4,q5,h } \\nF={h } \\n∑={a,b} \\n \\nΓ={ a,b,∆} \\n \\nδ : Transition table : \\n \\nstate a b Δ \\nqs - - (q0, Δ,R) \\nq0 (q1, Δ,R) (q4, Δ,R) (h, Δ,R) \\nq1 (q1,a,R) (q1,b,R) (q2,B,L) \\nq2 (q3, Δ,L)  (h, Δ,R) \\nq3 (q3,a,L) (q3,b,L) - \\nq4 (q4,a,R) (q4,b,R) (q6, Δ,L) \\nq5 - (q3, Δ,L) (h, Δ,R) \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 84}, page_content='9 \\n \\nInstantaneous Description: \\n \\nString: aba \\n \\nSequence of Moves for aba \\n \\n(qs, ∆ aba ∆) Ⱶ (q0, ∆ a b a ∆) \\n \\nⱵ (q1, ∆ ∆ b a ∆) \\nⱵ(q1, ∆ ∆ b a ∆) \\nⱵ(q1, ∆ ∆ b a ∆) \\nⱵ(q2, ∆ ∆ b a∆) \\nⱵ(q3, ∆ ∆ b∆∆) \\nⱵ(q3, ∆ ∆ b∆∆) \\nⱵ(q0, ∆ ∆ b∆∆) \\nⱵ(q4, ∆ ∆ ∆∆∆) \\nⱵ(q5, ∆ ∆ ∆∆∆) \\nⱵ(h, ∆ ∆ ∆∆∆) \\nAccepted \\n3. L= { x ∈ {a,b} * | x contains the sub string aba } \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 85}, page_content='10 \\n \\n4. L={x={a,b}* | x ends with an abb} \\n \\nR.E=(a+b)*abb \\n \\n5. Construct a Turing machine to copy a string \\nInput Tape: \\n \\n∆ a b a ∆ ∆ ∆ ∆ ∆ ……. \\nOutput Tape: \\n \\n \\n \\n∆ a b a ∆ a b a ∆ ……. \\n \\n \\n \\n∆aba∆∆∆∆ \\n \\n∆aba∆∆∆∆ \\n \\n∆Aba∆∆∆∆ \\n \\n∆Aba∆∆∆∆ \\n \\n∆Aba∆∆∆∆ \\n \\n∆Aba∆∆∆∆ \\n \\n∆Aba∆a∆∆ \\n \\n∆Aba∆a∆∆ \\n \\n∆Aba∆a∆∆ \\n \\n∆Aba∆a∆∆ \\n \\n∆Aba∆a∆∆ \\n \\n∆ABa∆a∆∆ \\n \\n∆ABa∆a∆∆ \\n \\n∆ABa∆∆a∆∆ \\n \\n∆ABa∆a∆∆∆ '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 86}, page_content='11 \\n \\n∆ABa∆ab∆∆ \\n \\n∆ABa∆ab∆∆ \\n \\n∆ABa∆ab∆∆ \\n \\n∆ABa∆ab∆∆ \\n \\n∆ABa∆ab∆∆ \\n \\n∆ABA∆ab∆∆ \\n \\n∆ABA∆ab∆∆ \\n \\n∆ABA∆ab∆∆ \\n \\n∆ABA∆ab∆∆ \\n \\n∆ABA∆aba∆ \\n \\n∆ABA∆aba∆ \\n \\n∆ABA∆aba∆ \\n \\n∆ABA∆aba∆ \\n \\n∆ABA∆aba∆ \\n \\n∆ABA∆aba∆ \\n \\n∆ABa∆aba∆ \\n \\n∆Aba∆aba∆ \\n \\n∆aba∆aba∆ \\n \\n∆Aba∆a∆∆ \\n \\n∆ABa∆ab∆ \\n \\n∆ABA∆aba \\n \\n∆aba∆aba '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 87}, page_content='12 \\n \\n \\n \\n \\n \\nDefine Tuples \\n \\nqs-start state \\nQ={qs,q0,q1,q2,q3,q4,q5,q6,q7,q8,h}} \\nF={h } \\n∑={a,b} \\n \\nΓ={ a,b,A.B,∆} \\n \\nδ : Transition table : \\n \\nStates a b A B Δ \\nq0 - - - - (q1, Δ,R) \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 88}, page_content='13 \\n \\nq1 (q2,A,R) (q3,B,R) - - (q8, Δ,L) \\nq2 (q2,a,R) (q2,b,R) - - (q4, Δ,R) \\nq3 (q3,a,R) (q3,b,R) - - (q5, Δ,R) \\nq4 (q4,a,R) (q4,b,R) - - (q6,a,L) \\nq5 (q5,a,R) (q5,b,R) - - (q6,b,L) \\nq6 (q6,a,L) (q6,b,L) - - (q7, Δ,L) \\nq7 (q7,a,L) (q7,b,L) (q1,A,R) (q1,B,R) - \\nq8 - - (q8,a,L) (q8,b,L) - \\n \\n \\nTrace the moves: aba \\n \\n(q0, Δaba Δ Δ Δ Δ Δ) |-(q1, ΔabaΔΔΔΔΔ) \\n(q2, ΔAba Δ Δ Δ Δ) |-(q2, ΔAba ΔΔΔΔΔ) \\n|-(q2, ΔAba ΔΔΔΔΔ) |-(q4, ΔAba  ΔΔΔΔ) \\n \\n|-(q6, ΔAba Δa ΔΔ) |-(q7, ΔAba  Δa ΔΔ ) \\n \\n|-(q7, ΔAba  Δa ΔΔ ) |-(q7, ΔAba  Δa ΔΔ ) \\n \\n|-(q1, ΔAba  Δa ΔΔ )   |-(q3, ΔABa  Δa ΔΔ ) \\n \\n|-(q3, ΔABa Δ a ΔΔ ) |-(q5, ΔABa Δ a ΔΔ ) \\n \\n|-(q5, ΔABa  Δ a Δ Δ )   |-(q6, ΔABa  Δ a b Δ ) \\n \\n|-(q6, ΔABa  Δ a b Δ )  |-(q7, ΔAB a  Δ a b Δ ) \\n \\n|-(q7, ΔAB a  Δ a b Δ )  |-(q1, ΔAB a  Δ a b Δ ) \\n \\n|-(q2, ΔAB A  Δ a b Δ )  |-(q4, ΔAB A  Δ a b Δ ) \\n \\n|-(q4, ΔAB A  Δ a b Δ )  |-(q4, ΔAB A  Δ a b Δ ) \\n \\n|-(q6, ΔAB A  Δ a b a )  |-(q6, ΔAB A  Δ a b a ) \\n \\n|-(q6, ΔAB A  Δ a b a )  |-(q7, ΔAB A  Δ a b a ) \\n \\n|-(q1, ΔAB A  Δ a b a )  |-(q8, ΔAB A  Δ a b a ) '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 89}, page_content='14 \\n \\n|-(q8, ΔAB a Δ a b a ) |-(q8, ΔAb a Δ a b a ) \\n \\n|-(q8, Δ ab a Δ a b a ) |-(h, Δ ab a Δ a b a ) \\n \\n \\n6. Turing machine to construct n mod 2 where n=|x|. \\nEven: \\n∆ 1 1 1 1 ∆ ∆ ∆ ∆ ……. \\nOdd: \\n \\n∆ 1 1 1 ∆ ∆ ∆ ∆ ∆ ……. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nDefine Tuple: \\n \\n \\n \\n(Q, Γ, ∑, δ, q0, B, F) \\n \\nwhere – \\n \\nQ- { q0,q1,q2,q3,q4,h} \\nΓ – {∆,1} \\n∑ - {1} \\n \\n∆ – blank symbol \\nq0 – Start state \\nh – Final state \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 90}, page_content='15 \\n \\nδ: \\nSTATES 1 ∆ \\nq0 - (q1,∆,R) \\nq1 (q1,1,R) (q2,∆,L) \\nq2 (q3,∆,L) (h,∆,S) \\nq3 - (q4,∆,R) \\nq4 - (h,1,S) \\n \\n \\n7. Construct a Turing machine to delete a symbol \\nInput: ababba \\n∆ a b a b B a ∆ ∆ ∆ ∆ ∆ ….. \\n \\n \\n∆ a b ∆ b b a ∆ ∆ ∆ ∆ ∆ ∆ ….. \\n \\n \\n∆ a b b b a ∆ ∆ ∆ ∆ ∆ ∆ …… \\n \\nExecution Logic: \\n \\nΔ bab Δ \\nΔ bab Δ \\nΔ Δ a b Δ \\nΔ Δ a b Δ \\nΔ Δ a b Δ \\nΔ Δ a b Δ \\nΔ Δ a Δ Δ \\nΔ Δ b Δ Δ \\na b Δ Δ - HALT '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 91}, page_content='16 \\n \\n \\n \\n \\nDefine Tuple: \\n \\n(Q, Γ, ∑, δ, q0, B, F) \\n \\nwhere – \\n \\nQ- { q0,q1,q2,q3,q4,h} \\nΓ – {∆,1} \\n∑ - {1} \\n \\n∆ – blank symbol \\nq0 – Start state \\nh – Final state \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 92}, page_content='17 \\n \\nTransition Table: δ \\n \\n \\n \\n \\nSTATES a b ∆ \\nq0 (q1,∆,R) (q1,∆,R) (q1,∆,R) \\nq1 (q1,a,R) (q1,b,R) (q2,∆,L) \\nq2 (qa,∆,L) (qb,∆,L) (h,∆,S) \\nqa (qa,a,L) (qb,a,L) (h,a,S) \\nqb (qa,b,L) (qb,b,L) (h,b,S) \\n \\n \\n \\nTrace the moves: \\n \\n(q0, Δ aba Δ) |- (q1, Δ aba Δ ) \\n \\n|- (q2, Δ Δ b a Δ ) \\n \\n|- (q2, Δ Δ b a Δ ) \\n \\n|- (q2, Δ Δ b a Δ ) \\n \\n|- (q3, Δ Δ b a Δ ) \\n \\n|- (q4, Δ Δ b Δ Δ ) \\n \\n|- (q5, Δ Δ a Δ Δ ) \\n \\n|- (q6, Δ b a Δ Δ ) - HALT \\n \\n \\n8. Construct a Turing machine for the language , L={SS | Sϵ{a,b}*} \\n \\nThe problem is divided into 2 parts: \\n \\n(i) Finding and marking the middle of the string \\n \\n(ii) Comparing the 2 halves. \\n \\n∆ a b b a b b ∆ ∆ ∆ ∆ ∆ ….. '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 93}, page_content='18 \\n \\n \\n \\n∆ a b b a b b ∆ ∆ ∆ ∆ ∆ ….. \\n \\n \\n∆ a b b A B B ∆ ∆ ∆ ∆ ∆ ….. \\n \\n \\nΔ a b b a b b Δ \\nΔ A b b a b b Δ \\nΔ A b b a b B Δ \\nΔ A B b a b B Δ \\nΔ A B b a b B Δ \\nΔ A B b a B B Δ Δ \\nA B b a B B Δ Δ A \\nB B a B B Δ Δ A \\nB B A B B Δ \\nΔ A B B A B B Δ – Mid point \\nΔ a b b A B B Δ – Mid point \\nΔ A b b A B B Δ \\nΔ  A b b Δ B B Δ \\nΔ  A B b Δ  Δ B Δ \\nΔ  A B B Δ  Δ Δ  Δ \\nΔ  A B B Δ  Δ Δ  Δ \\n \\n \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 94}, page_content='19 \\n \\nDefine Tuple: \\n \\n(Q, Γ, ∑, δ, q0, B, F) \\n \\nwhere – \\n \\nQ- { q0,q1,q2,q3,q4,q5,q6,q7,q8,q9,q10} \\nΓ – {∆,a,b,A,B} \\n∑ - {1} \\n \\n∆ – blank symbol \\nq0 – Start state \\nq10– Final state \\nTransition Table: δ \\n \\n \\n \\n \\nSTATES a b A B ∆ \\nq0 - - - - (q1,∆,R) \\nq1 (q1,A.R) (q1.B.R) (q5,A,L) (q5,B,L) (q10,∆.S) \\nq2 (q2,a,R) (q2.b.R) (q3,A,L) (q3,B,L) (q3,∆,L) \\nq3 (q4,A,L) (q4,B,L) - - - \\nq4 (q4,a,L) (q4,a,L) (q1,A,R) (q1,B,R)  \\nq5 - - (q5,a,L) (q5,b,L) (q6,∆,R) \\nq6 (q7,A,R) (q8,B,R) - - - \\nq7 (q7,a,R) (q7,b,R) (q9,∆,L)  (q7,∆,R) \\nq8 (q8,a,R) (q8,b,R) - (q9,∆,L) (q8,∆,R) \\nq9 (q9,a,L) (q9,b,L) (q6,A,R) (q6,B,R) (q9,∆,L) \\n \\nTrace the given string : abbabb '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 95}, page_content='20 \\n \\n9. Construct a turing machine for subtraction \\nf(m,n) = m-n , m>n \\n0 , m≤n \\n \\nCase 1: m>n \\n \\nInput tape: \\n \\nΔ 0 0 0 1 0 0 Δ ….. \\nOutput Tape: \\n \\nΔ Δ Δ Δ 0 Δ Δ Δ ….. \\n \\nCase 2: m<=n \\n \\nInput tape: \\n \\nΔ 0 0 1 0 0 0 Δ Δ ….. \\nOutput Tape: \\n \\nΔ Δ Δ Δ Δ Δ Δ Δ ….. \\n \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 96}, page_content='21 \\n \\n3.Variations of Turing Machine \\n \\n1. Multiple track Turing Machine: \\n\\uf0b7 A k-tack Turing machine(for some k>0) has k-tracks and one R/W head that reads and \\nwrites all of them one by one. \\n\\uf0b7 A k-track Turing Machine can be simulated by a single track Turing machine \\n \\na b a b … \\nb c a a … \\na a a a …. \\n \\n \\n \\n2. Two-way infinite Tape Turing Machine: \\nA two way infinite tape turing machine is a turing machine with it’s a input tape infinite in both \\ndirections, the other components being the same as that of the basic model. \\n\\uf0b7 Infinite tape of two-way infinite tape Turing machine is unbounded in both directions left \\nand right. \\n\\uf0b7 Two-way infinite tape Turing machine can be simulated by one-way infinite Turing \\nmachine (standard Turing machine). \\n \\n \\n………        …… \\n \\n \\n \\n3. Multi-tape Single-head Turing Machine: \\n\\uf0b7 It has multiple tapes and controlled by a single head. \\n\\uf0b7 The tape head scans the same position on all tapes. \\n \\n      \\n \\n \\n        \\nFC \\nFC '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 97}, page_content='22 \\n \\n4. Multi-tape Multi-head Turing Machine: \\n \\n \\n \\n \\n\\uf0b7 The multi-tape Turing machine has multiple tapes and multiple heads \\n\\uf0b7 Each tape controlled by separate head \\n\\uf0b7 Multi-Tape Multi-head Turing machine can be simulated by standard Turing \\n \\n5. Multi-head Turing Machine: \\n\\uf0b7 A multi-head Turing machine contain two or more heads to read the symbols on the same \\ntape. \\n\\uf0b7 In one step all the heads sense the scanned symbols and move or write independently. \\n\\uf0b7 Multi-head Turing machine can be simulated by single head Turing machine. \\n \\n          \\n \\n6. Non-deterministic Turing Machine: \\n\\uf0b7 A non-deterministic Turing machine has a single, one way infinite tape. \\n\\uf0b7 For a given state and input symbol has atleast one choice to move (finite number of choices \\nfor the next move), each choice several choices of path that it might follow for  a given \\ninput string. \\n\\uf0b7 A non-deterministic Turing machine is equivalent to deterministic Turing machine. \\n \\n \\n7. Offline Turing Machine \\n\\uf0b7 It is a multitape turing machine whose input tape is read only (writing is not allowed). \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 98}, page_content='23 \\n \\n\\uf0b7 An offline Turing machine can simulate any turing machine A by adding one more tape \\nthan Turing machine A. The reason for using an extra tape is that the offline Turing machine \\nmakes a copy of its own input into the extra tape and it then simulates Turing machine A as if \\nthe extra tape were A’s input. \\n \\n4. Universal Turing Machine \\n \\nA UTM is a specified Turing machine that can simulate the behavior of any TM. \\nA UTM is capable of running any algorithm. \\nIt is a Turing Machine whose input consists of 2 parts: \\n \\n\\uf0b7 A string specifying some special purpose Turing Machine, T1. \\n\\uf0b7 A string Z that is an input to T1. \\nThe Turing Machine, Tu then simulates the processing of Z by T1. \\n \\n4.1. Construction of Tu:  ∑={0,1} \\nStep 1: Formulate a notational system \\n\\uf0b7 For each tape symbol (including ∆) as string of 0’s \\n\\uf0b7 For each state (including h) \\n\\uf0b7 3 directions \\n\\uf0b7 For beginning of string and ending of string – 11 \\n\\uf0b7 For comma, encoding is 1 \\ne - encoding function \\nTu – represents the Universal Turing Machine \\n \\nT1 – represents the name of the special Turing machine \\n \\n \\n \\n \\n4.2. Constuct a UTM for the given Turing Machine \\nTu=e(T1).e(Z) '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 99}, page_content='24 \\n \\n \\n \\n \\n \\nEncoding: \\n \\nFor I/P symbols: \\n \\n∆ - 0 \\n \\na -00 \\n \\nb -000 \\n \\nFor each state: \\nh - 0 \\n \\nq0 - 00 \\n \\nq1 - 000 \\n \\nq2– 0000 \\n \\nFor directions \\n \\nS-0 \\nL-00 \\nR -000 \\n \\nTransition Function \\nδ(q0,∆)=(q1,∆,R) \\n00101000101000 \\nδ(q1,b)=(q1,b,R) \\n0001000100010001000 \\nδ(q1,a)=(q2,b,L) '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 100}, page_content='25 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\ne(T1)= \\n \\n \\n \\nZ=bba \\n000100100001000100 \\n \\nδ(q1,∆)=(q2, ∆,L) \\n000101000010100 \\nδ(q2,b)=(q2,b,L) \\n00001000100001000100 \\nδ(q2,∆)=(h,∆,S) \\n00001001010 \\n \\n001010001010001100010001000100010001100010010000100010011000101000010100 \\n11000010001000010001001100001001010 \\n \\ne(Z)=0001000100 \\nTu=e(T1).e(Z) \\n=1100101000101000110001000100010001000110001001000010001001100010100001 \\n010011000010001000010001001100001001010.11000100010011 \\nFor any input string Tu will halt if and only if T halts on input Z. \\n \\nOutput from Tu is in the encoded form of the output produced by T on input Z. '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 101}, page_content=' \\n \\nSCHOOL OF COMPUTING \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUNIT – V – Theory of Computation – SCSA1302 '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 102}, page_content=' \\n \\n \\nRECURSIVE LANGUAGES AND UNDECIDABILITY  \\nRecursively enumerable and recursive languages – Properties of  Recursively enumerable and \\nrecursive languages - Enumerating a language.  Introduction to Undecidability - Halting problem-\\nUndecidability of Post correspondence problem (PCP)-Modified PCP -Rice Theorem. \\n \\n1. Recursively Enumerable (REL ) & Recursive Languages (R L) \\n \\nRecursive Language:  \\n \\n \\n \\nRecursively Enumerable Language:  \\n \\n \\n \\n \\nTheorem1: \\nEvery recursive language is Recu rsively enumerable.  \\n \\n \\n \\n \\nIf T is TM recognizing L(RL) then we can get a TM that accepts the language L by modifying T so that \\nwhen the output is 0 it does not enter the reject state but enters into an infinite loop. \\n \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 103}, page_content=' \\n \\nTheorem 2: \\nEvery REL is not recursive.  \\n \\n \\n \\nTheorem 3: \\nThe complement of a RL is recursive (or) If L is recursive, so is L ′. \\n \\n \\nLet L be a Recursive Language and M be the TM that halts on all inputs and accepts L. \\n\\uf0b7 Construct M1 for L′. \\n\\uf0b7 M accepts and halts for Yes, then M′ rejects and halts. \\n\\uf0b7 M rejects and halts for N, then M′ accepts and halts. \\n \\nTheorem 4: \\ni. Union of two recursive  languages  is recursive.  \\nii. Union of two recursively  enumerable  languages  is REL. \\niii. Intersection of two recursively enumerable languages is REL. \\n \\ni) Union of two recursive  languages  is recursive.  \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 104}, page_content=' \\nLet L1 and L2 be the Recursive languages accepted by TMs M1 and M2. \\n \\nConstruct M: \\n\\uf0b7 It first simulates M1,If Yes than M accepts. \\n\\uf0b7 If M1 rejects, then M simulates M2 and accepts if and only if M2 accepts. \\n\\uf0b7 i.e) M accepts L1 U L2. \\n \\nii ) Union of two Recursively Enumerable L anguages is REL.  \\n \\n \\n \\n\\uf0b7 Let L1 and L2 be the Recursive Enumerable languages accepted by TMs M1 and M2. \\n\\uf0b7 M simultaneously simulates M1 and M2. \\n\\uf0b7 If either accepts, then M accepts. i.e. M accepts L1 U L2. \\n \\niii) Intersection of two recursively enumerable languages is REL. \\n \\n \\n \\n\\uf0b7 Let L1 and L2 be the Recursive Enumerable languages accepted by TMs M1 and M2. \\n\\uf0b7 M halts if both M1 and M2 halts. \\n\\uf0b7 M will never halt if either M1 or M2 enter into infinite loop. \\n\\uf0b7 ( i.e.) M accepts L1 \\n  L2. \\n \\n \\n \\n \\n \\n \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 105}, page_content=' \\n \\nTheorem 5: \\nIf a Language  L and its complement  L′ are both Recursively  Enumerable,  then L and hence L′ are \\nrecursive. \\n \\n \\n \\n\\uf0b7 Let M1 and M2 be the TMs accepting L1 and L2 respectively. \\n\\uf0b7 M simultaneously simulates M1 and M2. \\n\\uf0b7 M1 accepts L and M2 accepts L′ \\n \\n2. An Unsolvable Decision Problem:  \\n \\nA Turing Machine can solve decision problems. \\n \\nEg: Given x ε {a, b}* , Is x an element of Palindrome ? \\n \\nInstance of a problem \\n- It is a particular string x , so that when the string is provided as input to the TM, the \\nanswer is “YES “ or “NO” \\n- For more complicated problems to be solved by a TM, instances may need to be encoded \\nover the input alphabet of the machine. \\n \\nHow TM solves a decision problem P : \\n \\n \\ni/p string  x \\n Yes-instance of P    \\nNo-instance of P \\nDefinition 1: Self Accepting Language (SA ) \\n \\nSA = {w ε {0,1}* | w= e(T) for some TM T and w ε L(T) } \\nWhere w is any string \\ne( T ) is the encoding function \\n-If the same input is given to itself (TM) and if output is 1, the TM accepts its own input. (i.e) \\nTM accepts its own encodings e(T). \\n \\nTM '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 106}, page_content='Definition 2: Non-Self Accepting Language (NSA) \\nNSA = {w ε { 0,1}* | w= e(T) for some TM T and w ε L(T) }. \\n \\nDefinition 3 : Solvable Problem \\n \\nA Decision problem is solvable, if there is a algorithm capable of deciding every instance. \\nRecursive language yields solvable DP. \\n \\n \\nDefinition 4: Unsolvable Problem \\n \\nA Decision problem is unsolvable, if there is no algorithm capable of deciding every instance. Non-\\nRecursive language yields solvable DP. \\n \\nTheorem 1 : \\nThe language NSA is not recursively enumerable. \\n \\nProof by contradiction: \\nAssume NSA is REL. \\nThen, let L be a NSA and T be a TM accepting L. \\nThen, L(T) = NSA and w ε L(T) \\nBut w ε L(T), since is not of the form e(T). \\nThen w ε NSA, is not possible, which implies our assumption is false. Hence, \\nNSA is not REL. \\n \\nTheorem 2: \\nThe language SA is Recursively Enumerable but not Recursive \\n \\nProof: \\nW.K.T: \\n1. If L is recursive, then L’ is  also  recursive. \\n2. Every RL is also REL. \\n3. NSA is not REL. \\n \\n-If SA is recursive, then NSA is also recursive, then NSA is also REL. \\n-But by 3, NSA is not REL. \\n-Then, NSA is not recursive and not REL. \\n-Let T simulate processing w=e(T). \\n-T halts if w=e(T) & T loops forever if w ε e(T). \\n-To conclude, SA is REL but not Recursive. \\n \\n \\n \\n \\n '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 107}, page_content=' \\nDefinition 5: Reducing One Decision Problem to Another \\n \\nSuppose   P1 and P2 are decision problems. We say P1 is reducible to P2 (P1 ≤ P2) if there is an \\nalgorithm that finds, for an arbitrary instance I of P1, an instance F (I ) of P2, such that for every I , the \\nanswers for the two instances are  the same, or  I is a yes-instance of P1 if and only if F (I ) is  a yes-\\ninstance of P2. \\nDefinition 6: Reducing One Language to Another \\n \\nIf L1 and L2 are languages over alphabets ∑1 and ∑2, respectively, we say L1 is reducible to L2 (L1 ≤ L2) \\nif there is a Turing-computable function f : ∑1→ ∑2*, such that  for  every  x ∈ ∗ 1 , x ∈ L   1  if and only if f (x) \\n∈ L2 . \\nTheorem 3: \\nShow that the Accepts problem is unsolvable. \\n \\nIn order to show Accepts is unsolvable it is sufficient to show Self-Accepting ≤ Accepts An instance \\nof Self-Accepting is a TM T . A reduction to Accepts means finding a pair F (T ) = (T1, y) such  that T \\naccepts e(T ) if and only if \\nT1 accepts y. Letting T1 = T and y = e(T ) gives us such a pair, and F (T ) = (T , e(T )) can be obtained \\nalgorithmically from T ; therefore, F is a reduction from Self-Accepting to Accepts. \\nTheorem 4: \\nShow that Halting Problem is unsolvable. \\n \\nIn order to prove that Halts is unsolvable, it is sufficient to show that Accepts ≤ Halts . With an arbitrary \\ninstance (T, x) of Accepts where T is a TM and x is a string. The pair (T , x) = (T1, y), an instance of Halts \\nsuch that the two answers are the same: T accepts x if and only if T1 halts on input y. T1 should somehow \\nbe defined in terms of T .y should be defined in terms of x . \\nLet y to be x. TM T1 is defined such that for every x, T accepts x if and only if T1 halts on x. A \\nreformulation of this statement is: (i) if T accepts x, then T1 halts on x, and (ii) if T doesn’t accept \\nx, then T1 doesn’t halt on x. \\nThe Post Correspondence Problem (PCP) \\n \\nDefinition 7 : \\nAn instance of Post’s correspondence problem (PCP) is a set {(α1, β1), (α2, β2), . . . , (αn, βn)} of pairs, \\nwhere n ≥ 1 and the αi’s and βi’s are all non-null strings over an alphabet . \\nThe decision  problem : \\n Given an instance of this type, does there exist a positive integer k and a sequence of integers i1, i2, ...,ik \\nwith each ij satisfying 1 ≤ ij ≤ n, satisfying '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 108}, page_content='αi1αi2 ...αik = βi1βi2 ...βik \\n \\n \\nThe PCP decision problem is a combinatorial problem involving pairs of strings not related to Turing \\nmachines. The figure below shows a sample instance. Each of the five rectangles in the Figure is called \\na domino, and assume that there is an unlimited supply of each of the five. \\n \\n \\n \\nThe question is whether it is possible to make a horizontal line of one or more dominoes with \\nduplicates allowed, so that the string obtained by reading across the top halves matches the one  \\nobtained by reading across the bottom. \\nSolution: \\n \\n \\n10 1 01 0 100 100 0 100 \\n101 010 100 10 0 0 10 0 \\n \\n \\nDefinition 8: \\n \\nAn instance of the modified Post correspondence problem (MPCP) looks exactly like an instance of PCP, \\nbut now the sequence of integers is required to start with 1. The question can be formulated this  \\nway: \\nDoes there exist a positive integer k and a sequence i2, i3, ... , ik such that Instances of PCP and MPCP are \\ncalled correspondence systems and modified correspondence systems, respectively. \\nFor an instance of either type, if it is a yes-instance we will say that there is a match for the instance, \\nor that the sequence of subscripts is a match, or that the string formed by the αij ’s represents a match. \\nα1αi2 ...αik = β1βi2 ...βik \\n \\n \\n \\n \\n \\n \\n \\n101 \\n10 \\n \\n100 \\n01 \\n \\n10 \\n \\n \\n100 \\n \\n010 \\n '),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 109}, page_content='More Unsolvable Problems  \\n \\n1. Assuming L is a recursively enumerable language): Accepts L: Given a TM T , is L(T ) = L? \\n \\n2. Accepts something: Given a TM T, is there at least one string in L(T )?\\\\ \\n \\n \\n3.  Accepts two or more : Given a TM T , does L(T ) have at least two elements? \\n \\n4. Accepts finite: Given a TM T, is L(T ) finite? 5. Accepts Recursive: Given a TM T, is L(T )    \\n(which by definition is recursively enumerable) recursive. \\n5. MPCP ≤ PCP. \\n \\n6. Accepts ≤ MPCP. \\n \\n \\n \\nHalting Problem: \\nIn the theory of computability, the problem of halting is the question of deciding, from an arbitrary \\ncomputer program description and an input, whether the program will finish running or continue to \\nrun indefinitely. In 1936, Alan Turing proved that there could not be a general algorithm for all \\npossible program-input pairs to solve the halting problem. \\n \\nGiven a program and an input to the program, determine if the program will eventually halt when it \\nis given that input. \\n    \\n \\n                                                                                           Loop \\n                              Input                                                       \\n                                                                                            Halt    \\n \\n \\nHalting problem is unsolvable \\n \\nProof by Contradiction \\n1. Assume the statement is true. \\n2. Solve the problem. \\n3. Check if there is a contradiction. \\nProof: \\n1. Assume it is possible to solve the halting problem. \\nAssume it is possible to construct a machine H that solves the halting problem. \\nH receives 2 inputs: \\n P- program \\n I – input to the program P \\n           H machine gives an answer ‘yes’ if program P halts on input I. \\n           If it goes into an infinite loop, H gives answer no.        \\n \\n \\n \\n \\n   Program \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 110}, page_content='                        \\n \\n      \\n                              P                                                        Yes \\n   \\n                               I                                           No \\n \\n \\n \\n \\n \\n2. Create a new machine using machine H as basis. \\n      Let the machine be X. \\n      Add a condition at the end of machine H such that: \\n-If it outputs a ‘Yes’ answer it will loop. \\n- If it outputs a ‘No’ answer it will halt. \\n \\n \\n \\n \\nIf we give the program of machine X to itself along with the given set of inputs which has already \\nbeen generated. \\n \\n \\n \\nIf the output of the machine H inside X is ‘Yes’, it means X will loop which contradicts the result \\nof machine H. \\n“Yes means it will halt but it didn’t”  \\nIn the same way, if the result of machine H is ‘No’, it means X will halt which again contradicts the \\nresult of H. \\n“No means it will not halt but it halted” \\nThis machine H does exist and the halting problem is unsolved. \\n \\n \\n \\n \\n \\n \\n         H \\n'),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 111}, page_content=\"Rice Theorem \\nRice theorem states that any non -trivial semantic property of a language which is recognized by a \\nTuring machine is undecidable. A property,  P, is the language of all Turing machines that satisfy \\nthat property. \\nDefinition 9 \\nIf P is a non -trivial property, and the language holding the property, Lp  , is recognized by Turing \\nmachine M, then Lp = {<M> | L(M) ∈ P} is undecidable. \\n \\n \\n \\nProperties \\n\\uf0b7 Property of languages, P, is simply a set of languages. If any language belongs to P (L ∈ P), \\nit is said that L satisfies the property P. \\n\\uf0b7 A property is called to be trivial if either it is not satisfied by any recursively enumerable \\nlanguages, or if it is satisfied by all recursively enumerable languages. \\n\\uf0b7 A non-trivial property is satisfied by some recursively enumerable languages and are not \\nsatisfied by others. Formally speaking, in a non -trivial property, where L ∈ P, both the \\nfollowing properties hold: \\no Property 1 − There exists Turing Machines, M1 and M2 that recognize the same \\nlanguage, i.e. either ( <M1>, <M2> ∈ L ) or ( <M1>,<M2> ∉ L ) \\no Property 2 − There exists Turing Machines M1 and M2, where M1 recognizes the \\nlanguage while M2 does not, i.e. <M1> ∈ L and <M2> ∉ L \\nProof: \\nSuppose, a property P is non-trivial and φ ∈ P. \\nSince, P is non-trivial, at least one language satisfies P, i.e., L(M0) ∈ P , ∋ Turing Machine M0. \\nLet, w be an input in a particular instant and N is a Turing Machine which follows − \\nOn input x \\n\\uf0b7 Run M on w \\n\\uf0b7 If M does not accept (or doesn't halt), then do not accept x (or do not halt) \\n\\uf0b7 If M accepts w then run M0 on x. If M0 accepts x, then accept x. \\nA function that maps an instance ATM = {<M,w>| M accepts input w} to a N such that \\n\\uf0b7 If M accepts w and N accepts the same language as M0, Then L(M) = L(M0) ∈ p \\n\\uf0b7 If M does not accept w and N accepts φ, Then L(N) = φ ∉ p \\nSince ATM is undecidable and it can be reduced to Lp, Lp is also undecidable. \\n \\n \\n \"),\n",
              " Document(metadata={'source': '/content/TOC.pdf', 'page': 112}, page_content=' \\n \\n \\n  ')]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "pages"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Splitter"
      ],
      "metadata": {
        "id": "05Dd4C4436_k"
      },
      "id": "05Dd4C4436_k"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "77KUe0qSmt5h",
      "metadata": {
        "id": "77KUe0qSmt5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbeab1f8-5d58-4c17-f317-3deef19b414a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "\n",
        "text_chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "len(text_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "bduwbig1mt9c",
      "metadata": {
        "id": "bduwbig1mt9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067d9536-c60f-4aab-8b15-17b4b7b41095"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/TOC.pdf', 'page': 0}, page_content='SCHOOL OF COMPUTING \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\n \\n \\n \\n  \\n \\n \\n \\n \\nUNIT – I – THEORY OF COMPUTATION – SCSA1302')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "text_chunks[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FSnv3gV3muBm",
      "metadata": {
        "id": "FSnv3gV3muBm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uO4dx_pNmuFt",
      "metadata": {
        "id": "uO4dx_pNmuFt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}